{"cells":[{"cell_type":"markdown","metadata":{"id":"UHg3b7Abcae0"},"source":["# Run me before Section 7-!"]},{"cell_type":"markdown","metadata":{"id":"qh131HdlXrAb"},"source":["##1.Data preparation\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":2815,"status":"ok","timestamp":1695178006963,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"c0vXuuNVVysp","outputId":"e774c09a-bcf9-4d9a-dda9-d2b9e0ce1922"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.13.0'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1199,"status":"ok","timestamp":1695178505389,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"ssS-f9_0gxxf","outputId":"6ae72279-e547-490d-87a2-d17d43af687d"},"outputs":[{"name":"stdout","output_type":"stream","text":["absl-py==1.4.0\n","aiohttp==3.8.5\n","aiosignal==1.3.1\n","alabaster==0.7.13\n","albumentations==1.3.1\n","altair==4.2.2\n","anyio==3.7.1\n","appdirs==1.4.4\n","argon2-cffi==23.1.0\n","argon2-cffi-bindings==21.2.0\n","array-record==0.4.1\n","arviz==0.15.1\n","astropy==5.3.3\n","astunparse==1.6.3\n","async-timeout==4.0.3\n","attrs==23.1.0\n","audioread==3.0.0\n","autograd==1.6.2\n","Babel==2.12.1\n","backcall==0.2.0\n","beautifulsoup4==4.11.2\n","bleach==6.0.0\n","blinker==1.4\n","blis==0.7.10\n","blosc2==2.0.0\n","bokeh==3.2.2\n","boto3==1.28.51\n","botocore==1.31.51\n","bqplot==0.12.40\n","branca==0.6.0\n","build==1.0.3\n","CacheControl==0.13.1\n","cachetools==5.3.1\n","catalogue==2.0.9\n","certifi==2023.7.22\n","cffi==1.15.1\n","chardet==5.2.0\n","charset-normalizer==3.2.0\n","chex==0.1.7\n","click==8.1.7\n","click-plugins==1.1.1\n","cligj==0.7.2\n","cloudpickle==2.2.1\n","cmake==3.27.4.1\n","cmdstanpy==1.1.0\n","colorcet==3.0.1\n","colorlover==0.3.0\n","colour==0.1.5\n","community==1.0.0b1\n","confection==0.1.2\n","cons==0.4.6\n","contextlib2==21.6.0\n","contourpy==1.1.0\n","convertdate==2.4.0\n","cryptography==41.0.3\n","cufflinks==0.17.3\n","cupy-cuda11x==11.0.0\n","cvxopt==1.3.2\n","cvxpy==1.3.2\n","cycler==0.11.0\n","cymem==2.0.7\n","Cython==3.0.2\n","dask==2023.8.1\n","datascience==0.17.6\n","db-dtypes==1.1.1\n","dbus-python==1.2.18\n","debugpy==1.6.6\n","decorator==4.4.2\n","defusedxml==0.7.1\n","distributed==2023.8.1\n","distro==1.7.0\n","dlib==19.24.2\n","dm-tree==0.1.8\n","docutils==0.18.1\n","dopamine-rl==4.0.6\n","duckdb==0.8.1\n","earthengine-api==0.1.368\n","easydict==1.10\n","ecos==2.0.12\n","editdistance==0.6.2\n","eerepr==0.0.4\n","en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n","entrypoints==0.4\n","ephem==4.1.4\n","et-xmlfile==1.1.0\n","etils==1.4.1\n","etuples==0.3.9\n","exceptiongroup==1.1.3\n","fastai==2.7.12\n","fastcore==1.5.29\n","fastdownload==0.0.7\n","fastjsonschema==2.18.0\n","fastprogress==1.0.3\n","fastrlock==0.8.2\n","filelock==3.12.2\n","Fiona==1.9.4.post1\n","firebase-admin==5.3.0\n","Flask==2.2.5\n","flatbuffers==23.5.26\n","flax==0.7.2\n","folium==0.14.0\n","fonttools==4.42.1\n","frozendict==2.3.8\n","frozenlist==1.4.0\n","fsspec==2023.6.0\n","future==0.18.3\n","gast==0.4.0\n","gcsfs==2023.6.0\n","GDAL==3.4.3\n","gdown==4.6.6\n","geemap==0.26.0\n","gensim==4.3.2\n","geocoder==1.38.1\n","geographiclib==2.0\n","geopandas==0.13.2\n","geopy==2.3.0\n","gin-config==0.5.0\n","glob2==0.7\n","google==2.0.3\n","google-api-core==2.11.1\n","google-api-python-client==2.84.0\n","google-auth==2.17.3\n","google-auth-httplib2==0.1.0\n","google-auth-oauthlib==1.0.0\n","google-cloud-bigquery==3.10.0\n","google-cloud-bigquery-connection==1.12.1\n","google-cloud-bigquery-storage==2.22.0\n","google-cloud-core==2.3.3\n","google-cloud-datastore==2.15.2\n","google-cloud-firestore==2.11.1\n","google-cloud-functions==1.13.2\n","google-cloud-language==2.9.1\n","google-cloud-storage==2.8.0\n","google-cloud-translate==3.11.3\n","google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=4ee197bfbe55e87b0e71294690f2afbca069ec0c14ddda174843893b4fbd6328\n","google-crc32c==1.5.0\n","google-pasta==0.2.0\n","google-resumable-media==2.6.0\n","googleapis-common-protos==1.60.0\n","googledrivedownloader==0.4\n","graphviz==0.20.1\n","greenlet==2.0.2\n","grpc-google-iam-v1==0.12.6\n","grpcio==1.57.0\n","grpcio-status==1.48.2\n","gspread==3.4.2\n","gspread-dataframe==3.3.1\n","gym==0.25.2\n","gym-notices==0.0.8\n","h5netcdf==1.2.0\n","h5py==3.9.0\n","holidays==0.32\n","holoviews==1.17.1\n","html5lib==1.1\n","httpimport==1.3.1\n","httplib2==0.15.0\n","humanize==4.7.0\n","hyperopt==0.2.7\n","idna==3.4\n","imageio==2.31.3\n","imageio-ffmpeg==0.4.8\n","imagesize==1.4.1\n","imbalanced-learn==0.10.1\n","imgaug==0.4.0\n","importlib-metadata==6.8.0\n","importlib-resources==6.0.1\n","imutils==0.5.4\n","inflect==7.0.0\n","iniconfig==2.0.0\n","intel-openmp==2023.2.0\n","ipyevents==2.0.2\n","ipyfilechooser==0.6.0\n","ipykernel==5.5.6\n","ipyleaflet==0.17.3\n","ipython==7.34.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.5.0\n","ipytree==0.2.2\n","ipywidgets==7.7.1\n","itsdangerous==2.1.2\n","jax==0.4.14\n","jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.14+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=09c439923a785df517e3f470158dd3e46de454a01eca80935eed4ba383b5e90a\n","jeepney==0.7.1\n","jieba==0.42.1\n","Jinja2==3.1.2\n","jmespath==1.0.1\n","joblib==1.3.2\n","jsonpickle==3.0.2\n","jsonschema==4.19.0\n","jsonschema-specifications==2023.7.1\n","jupyter-client==6.1.12\n","jupyter-console==6.1.0\n","jupyter-server==1.24.0\n","jupyter_core==5.3.1\n","jupyterlab-pygments==0.2.2\n","jupyterlab-widgets==3.0.8\n","kaggle==1.5.16\n","keras==2.13.1\n","keras-layer-normalization==0.16.0\n","keyring==23.5.0\n","kiwisolver==1.4.5\n","langcodes==3.3.0\n","launchpadlib==1.10.16\n","lazr.restfulclient==0.14.4\n","lazr.uri==1.0.6\n","lazy_loader==0.3\n","libclang==16.0.6\n","librosa==0.10.1\n","lightgbm==4.0.0\n","linkify-it-py==2.0.2\n","lit==16.0.6\n","llvmlite==0.39.1\n","locket==1.0.0\n","logical-unification==0.4.6\n","LunarCalendar==0.0.9\n","lxml==4.9.3\n","Markdown==3.4.4\n","markdown-it-py==3.0.0\n","MarkupSafe==2.1.3\n","matplotlib==3.7.1\n","matplotlib-inline==0.1.6\n","matplotlib-venn==0.11.9\n","mdit-py-plugins==0.4.0\n","mdurl==0.1.2\n","miniKanren==1.0.3\n","missingno==0.5.2\n","mistune==0.8.4\n","mizani==0.9.3\n","mkl==2023.2.0\n","ml-dtypes==0.2.0\n","mlxtend==0.22.0\n","more-itertools==10.1.0\n","moviepy==1.0.3\n","mpmath==1.3.0\n","msgpack==1.0.5\n","multidict==6.0.4\n","multipledispatch==1.0.0\n","multitasking==0.0.11\n","murmurhash==1.0.9\n","music21==9.1.0\n","natsort==8.4.0\n","nbclassic==1.0.0\n","nbclient==0.8.0\n","nbconvert==6.5.4\n","nbformat==5.9.2\n","nest-asyncio==1.5.7\n","networkx==3.1\n","nibabel==4.0.2\n","nltk==3.8.1\n","notebook==6.5.5\n","notebook_shim==0.2.3\n","numba==0.56.4\n","numexpr==2.8.5\n","numpy==1.23.5\n","oauth2client==4.1.3\n","oauthlib==3.2.2\n","opencv-contrib-python==4.8.0.76\n","opencv-python==4.8.0.76\n","opencv-python-headless==4.8.0.76\n","openpyxl==3.1.2\n","opt-einsum==3.3.0\n","optax==0.1.7\n","orbax-checkpoint==0.3.5\n","osqp==0.6.2.post8\n","packaging==23.1\n","pandas==1.5.3\n","pandas-datareader==0.10.0\n","pandas-gbq==0.17.9\n","pandocfilters==1.5.0\n","panel==1.2.2\n","param==1.13.0\n","parso==0.8.3\n","partd==1.4.0\n","pathlib==1.0.1\n","pathy==0.10.2\n","patsy==0.5.3\n","pexpect==4.8.0\n","pickleshare==0.7.5\n","Pillow==9.4.0\n","pip-tools==6.13.0\n","platformdirs==3.10.0\n","plotly==5.15.0\n","plotnine==0.12.3\n","pluggy==1.3.0\n","polars==0.17.3\n","pooch==1.7.0\n","portpicker==1.5.2\n","prefetch-generator==1.0.3\n","preshed==3.0.8\n","prettytable==3.8.0\n","proglog==0.1.10\n","progressbar2==4.2.0\n","prometheus-client==0.17.1\n","promise==2.3\n","prompt-toolkit==3.0.39\n","prophet==1.1.4\n","proto-plus==1.22.3\n","protobuf==3.20.3\n","psutil==5.9.5\n","psycopg2==2.9.7\n","ptyprocess==0.7.0\n","py-cpuinfo==9.0.0\n","py4j==0.10.9.7\n","pyarrow==9.0.0\n","pyasn1==0.5.0\n","pyasn1-modules==0.3.0\n","pycocotools==2.0.7\n","pycparser==2.21\n","pyct==0.5.0\n","pydantic==1.10.12\n","pydata-google-auth==1.8.2\n","pydot==1.4.2\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","PyDrive2==1.6.3\n","pyerfa==2.0.0.3\n","pygame==2.5.1\n","Pygments==2.16.1\n","PyGObject==3.42.1\n","PyJWT==2.3.0\n","pymc==5.7.2\n","PyMeeus==0.5.12\n","pymystem3==0.2.0\n","PyOpenGL==3.1.7\n","pyOpenSSL==23.2.0\n","pyparsing==3.1.1\n","pyperclip==1.8.2\n","pyproj==3.6.0\n","pyproject_hooks==1.0.0\n","pyshp==2.3.1\n","PySocks==1.7.1\n","pytensor==2.14.2\n","pytest==7.4.1\n","python-apt==0.0.0\n","python-box==7.1.1\n","python-dateutil==2.8.2\n","python-louvain==0.16\n","python-slugify==8.0.1\n","python-utils==3.7.0\n","pytorch-nlp==0.5.0\n","pytorch-pretrained-bert==0.6.2\n","pytz==2023.3.post1\n","pyviz_comms==3.0.0\n","PyWavelets==1.4.1\n","PyYAML==6.0.1\n","pyzmq==23.2.1\n","qdldl==0.1.7.post0\n","qudida==0.0.4\n","ratelim==0.1.6\n","referencing==0.30.2\n","regex==2023.6.3\n","requests==2.31.0\n","requests-oauthlib==1.3.1\n","requirements-parser==0.5.0\n","rich==13.5.2\n","rpds-py==0.10.2\n","rpy2==3.4.2\n","rsa==4.9\n","s3transfer==0.6.2\n","scikit-image==0.19.3\n","scikit-learn==1.2.2\n","scipy==1.11.2\n","scooby==0.7.2\n","scs==3.2.3\n","seaborn==0.12.2\n","SecretStorage==3.3.1\n","Send2Trash==1.8.2\n","seqeval==1.2.2\n","shapely==2.0.1\n","six==1.16.0\n","sklearn-pandas==2.2.0\n","smart-open==6.4.0\n","sniffio==1.3.0\n","snowballstemmer==2.2.0\n","sortedcontainers==2.4.0\n","soundfile==0.12.1\n","soupsieve==2.5\n","soxr==0.3.6\n","spacy==3.6.1\n","spacy-legacy==3.0.12\n","spacy-loggers==1.0.4\n","Sphinx==5.0.2\n","sphinxcontrib-applehelp==1.0.7\n","sphinxcontrib-devhelp==1.0.5\n","sphinxcontrib-htmlhelp==2.0.4\n","sphinxcontrib-jsmath==1.0.1\n","sphinxcontrib-qthelp==1.0.6\n","sphinxcontrib-serializinghtml==1.1.9\n","SQLAlchemy==2.0.20\n","sqlparse==0.4.4\n","srsly==2.4.7\n","statsmodels==0.14.0\n","sympy==1.12\n","tables==3.8.0\n","tabulate==0.9.0\n","tbb==2021.10.0\n","tblib==2.0.0\n","tenacity==8.2.3\n","tensorboard==2.13.0\n","tensorboard-data-server==0.7.1\n","tensorflow==2.13.0\n","tensorflow-datasets==4.9.2\n","tensorflow-estimator==2.13.0\n","tensorflow-gcs-config==2.13.0\n","tensorflow-hub==0.14.0\n","tensorflow-io-gcs-filesystem==0.33.0\n","tensorflow-metadata==1.14.0\n","tensorflow-probability==0.20.1\n","tensorstore==0.1.41\n","termcolor==2.3.0\n","terminado==0.17.1\n","text-unidecode==1.3\n","textblob==0.17.1\n","tf-slim==1.1.0\n","thinc==8.1.12\n","threadpoolctl==3.2.0\n","tifffile==2023.8.30\n","tinycss2==1.2.1\n","toml==0.10.2\n","tomli==2.0.1\n","toolz==0.12.0\n","torch @ https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a7a49d459bf4862f64f7bc1a68beccf8881c2fa9f3e0569608e16ba6f85ebf7b\n","torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=26692645ea061a005c57ec581a2d0425210ac6ba9f923edf11cc9b0ef3a111e9\n","torchdata==0.6.1\n","torchsummary==1.5.1\n","torchtext==0.15.2\n","torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=19ca4ab5d6179bbe53cff79df1a855ee6533c2861ddc7389f68349d8b9f8302a\n","tornado==6.3.2\n","tqdm==4.66.1\n","traitlets==5.7.1\n","traittypes==0.2.1\n","triton==2.0.0\n","tweepy==4.13.0\n","typer==0.9.0\n","types-setuptools==68.2.0.0\n","typing_extensions==4.5.0\n","tzlocal==5.0.1\n","uc-micro-py==1.0.2\n","uritemplate==4.1.1\n","urllib3==1.26.16\n","vega-datasets==0.9.0\n","wadllib==1.3.6\n","wasabi==1.1.2\n","wcwidth==0.2.6\n","webcolors==1.13\n","webencodings==0.5.1\n","websocket-client==1.6.2\n","Werkzeug==2.3.7\n","widgetsnbextension==3.6.5\n","wordcloud==1.9.2\n","wrapt==1.15.0\n","xarray==2023.7.0\n","xarray-einstats==0.6.0\n","xgboost==1.7.6\n","xlrd==2.0.1\n","xyzservices==2023.7.0\n","yarl==1.9.2\n","yellowbrick==1.5\n","yfinance==0.2.28\n","zict==3.0.0\n","zipp==3.16.2\n"]}],"source":["!pip freeze"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"elapsed":21046,"status":"ok","timestamp":1695179124757,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"15Vf-y09m6K1","outputId":"563db723-f0e2-4362-fd55-f3c85820799b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: httplib2==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n","Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.10/dist-packages (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-layer-normalization) (1.23.5)\n","Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: torch\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.23.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.28.51)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=0.4.1-\u003epytorch-pretrained-bert) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=0.4.1-\u003epytorch-pretrained-bert) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch\u003e=0.4.1-\u003epytorch-pretrained-bert) (16.0.6)\n","Requirement already satisfied: botocore\u003c1.32.0,\u003e=1.31.51 in /usr/local/lib/python3.10/dist-packages (from boto3-\u003epytorch-pretrained-bert) (1.31.51)\n","Requirement already satisfied: jmespath\u003c2.0.0,\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3-\u003epytorch-pretrained-bert) (1.0.1)\n","Requirement already satisfied: s3transfer\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3-\u003epytorch-pretrained-bert) (0.6.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003epytorch-pretrained-bert) (3.2.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003epytorch-pretrained-bert) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003epytorch-pretrained-bert) (1.26.16)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003epytorch-pretrained-bert) (2023.7.22)\n","Requirement already satisfied: python-dateutil\u003c3.0.0,\u003e=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore\u003c1.32.0,\u003e=1.31.51-\u003eboto3-\u003epytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=0.4.1-\u003epytorch-pretrained-bert) (2.1.3)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=0.4.1-\u003epytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003c3.0.0,\u003e=2.1-\u003ebotocore\u003c1.32.0,\u003e=1.31.51-\u003eboto3-\u003epytorch-pretrained-bert) (1.16.0)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn\u003e=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy\u003e=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.11.2)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval) (3.2.0)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["!pip install -U -q PyDrive\n","!pip install httplib2==0.15.0\n","!pip install keras-layer-normalization\n","!pip install pytorch-pretrained-bert pytorch-nlp\n","!pip install seqeval\n","\n","# install\n","# specify GPU device\n","%matplotlib inline\n","from datetime import datetime\n","from google.colab import auth\n","from google.colab import drive\n","from keras import backend as K\n","from keras import layers\n","from keras.layers import TimeDistributed\n","from keras_layer_normalization import LayerNormalization\n","#from keras_preprocessing.sequence import pad_sequences\n","from keras.utils import pad_sequences\n","from oauth2client.client import GoogleCredentials\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","#from pytorch_pretrained_bert import BertAdam, BertModel\n","#from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from seqeval.metrics import accuracy_score\n","from seqeval.metrics import classification_report as seqeval_classification_report\n","from seqeval.metrics import f1_score\n","from seqeval.metrics import precision_score\n","from seqeval.metrics import recall_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score as f_score\n","from sklearn.metrics import precision_score as pre_score\n","from sklearn.metrics import recall_score as re_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow import keras\n","from tensorflow.keras.optimizers import Adam\n","from torch import nn\n","from torch import optim\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torchvision import datasets, transforms\n","from tqdm import tqdm, trange\n","import glob\n","import h5py\n","import io\n","import keras.activations\n","import keras.applications\n","import keras.backend\n","import keras.callbacks\n","import keras.constraints\n","import keras.datasets\n","#import keras.engine\n","import keras.initializers\n","import keras.layers\n","import keras.losses\n","import keras.metrics\n","import keras.models\n","import keras.optimizers\n","import keras.preprocessing\n","import keras.regularizers\n","import keras.utils\n","#import keras.wrappers\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","import torch\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26113,"status":"ok","timestamp":1695178290870,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"hKsca2OP8xK2","outputId":"f9d1732d-51a4-470e-def8-9179301f6c96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1465,"status":"ok","timestamp":1695178292329,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"4M5vE7Wy80_k"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-a19120079d24\u003e\", line 3, in \u003ccell line: 3\u003e\n","    get_ipython().run_line_magic('cd', '/content/drive/My Drive/tri-model/MultiWOZ')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"\u003cdecorator-gen-85\u003e\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in \u003clambda\u003e\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-a19120079d24\u003e\", line 3, in \u003ccell line: 3\u003e\n","    get_ipython().run_line_magic('cd', '/content/drive/My Drive/tri-model/MultiWOZ')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"\u003cdecorator-gen-85\u003e\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in \u003clambda\u003e\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-a19120079d24\u003e\", line 3, in \u003ccell line: 3\u003e\n","    get_ipython().run_line_magic('cd', '/content/drive/My Drive/tri-model/MultiWOZ')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"\u003cdecorator-gen-85\u003e\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in \u003clambda\u003e\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["# %cd /content/drive/My Drive/hu_joint_nlu_multiturn/M2M\n","\n","%cd /content/drive/My Drive/tri-model/MultiWOZ"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":251},"executionInfo":{"elapsed":16,"status":"error","timestamp":1695178292330,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-600},"id":"kcx6l7yL8zFv"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["0\n","__main__\n","[]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-cff7a577cceb\u003e\", line 20, in \u003ccell line: 20\u003e\n","    train_data = pd.concat(train_data,ignore_index=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 331, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 368, in concat\n","    op = _Concatenator(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 425, in __init__\n","    raise ValueError(\"No objects to concatenate\")\n","ValueError: No objects to concatenate\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-cff7a577cceb\u003e\", line 20, in \u003ccell line: 20\u003e\n","    train_data = pd.concat(train_data,ignore_index=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 331, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 368, in concat\n","    op = _Concatenator(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 425, in __init__\n","    raise ValueError(\"No objects to concatenate\")\n","ValueError: No objects to concatenate\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"\u003cipython-input-14-cff7a577cceb\u003e\", line 20, in \u003ccell line: 20\u003e\n","    train_data = pd.concat(train_data,ignore_index=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 331, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 368, in concat\n","    op = _Concatenator(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 425, in __init__\n","    raise ValueError(\"No objects to concatenate\")\n","ValueError: No objects to concatenate\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["# drive.mount('/content/drive/')\n","# %cd /content/drive/My Drive/hu_joint_nlu_multiturn/MultiWOZ\n","\n","\n","files = glob.glob('data/train/dialogues_*.json')\n","train_data = []\n","print(len(train_data))\n","\n","print(__name__)\n","print(files)\n","\n","if __name__ == '__main__':\n","  #for fn in files[:-1]:    ########################### HW changed - there is some issue in file 012 causing this block to fail,\n","  for fn in files:\n","    print(fn)\n","    with open(fn, 'rb') as f:\n","        train_data.append(pd.read_json(fn))\n","        print(len(train_data))\n","\n","train_data = pd.concat(train_data,ignore_index=True)\n","\n","\n","files = glob.glob('data/dev/dialogues_*.json')\n","dev_data = []\n","\n","if __name__ == '__main__':\n","  for fn in files:\n","    with open(fn, 'rb') as f:\n","        dev_data.append(pd.read_json(fn))\n","\n","dev_data = pd.concat(dev_data,ignore_index=True)\n","\n","\n","files = glob.glob('data/test/dialogues_*.json')\n","test_data = []\n","\n","if __name__ == '__main__':\n","  for fn in files:\n","    with open(fn, 'rb') as f:\n","        test_data.append(pd.read_json(fn))\n","\n","test_data = pd.concat(test_data,ignore_index=True)\n","\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ik5lVLf6_TC"},"outputs":[],"source":["def get_slot_intent_domain(dataset):\n","  all_turns = []\n","  all_domains = []\n","  all_slots = []\n","  all_states = []\n","  for dialogue_id in range(len(dataset['turns'])):\n","    for frames in dataset['turns'][dialogue_id]:  # train_data['turns'][0][0]\n","      this_domain = []\n","      this_slot = []\n","      this_state = []\n","      for frame in frames['frames']:\n","        if len(frame['slots']):\n","          this_slot += frame['slots']\n","        if len(frame['slots']) or 'state' in frame and frame['state']['active_intent']!='NONE':\n","          this_domain.append(frame['service'])\n","        if 'state' in frame and frame['state']['active_intent']!='NONE':\n","          this_state.append(frame['state']['active_intent'])\n","\n","      if len(this_state) and len(this_domain):\n","        all_slots.append(this_slot)\n","        all_domains.append('-'.join(sorted(this_domain)))\n","        all_states.append('-'.join(sorted(this_state)))\n","        all_turns.append(frames['utterance'].lower())\n","\n","  slot_value_pairs = []\n","  for slots_id in range(len(all_slots)):\n","    slot_value_pair = ['O'] * len(all_turns[slots_id].split())\n","    for slot in all_slots[slots_id]:\n","      if 'start' in slot:\n","        marked_turn = (all_turns[slots_id][:slot['start']] + ' \u0026 ' + all_turns[slots_id][slot['start']:]).split()\n","        start_id = marked_turn.index('\u0026')\n","        slot_list = slot['value']\n","        if type(slot_list) == str:\n","          slot_len = len(slot_list.split())\n","          try:\n","            slot_value_pair[start_id] = 'B-'+slot['slot']\n","            if slot_len \u003e 1:\n","              slot_value_pair[start_id+1:start_id+slot_len] = ['I-'+slot['slot']]*(slot_len-1)\n","          except:\n","            print('Exception id:', slots_id)\n","            slot_value_pair[start_id-1] = 'B-'+slot['slot']\n","            if slot_len \u003e 1:\n","              slot_value_pair[start_id:start_id+slot_len-1] = ['I-'+slot['slot']]*(slot_len-1)\n","    slot_value_pairs.append(slot_value_pair)\n","  all_turns = [turn.split() for turn in all_turns]\n","  return all_turns, slot_value_pairs, all_states, all_domains"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":781,"status":"ok","timestamp":1678326332105,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"RAgPYLQXHG2B","outputId":"cc429974-a57f-480b-d37b-e301ea85efd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Exception id: 26486\n","Exception id: 27517\n","Exception id: 30931\n","Exception id: 32535\n","Exception id: 37215\n","Exception id: 38212\n","\n","Slots are: attraction-name, bus-departure, bus-destination, hospital-department, hotel-name, hotel-stars, hotel-type, restaurant-booktime, restaurant-food, restaurant-name, taxi-arriveby, taxi-departure, taxi-destination, taxi-leaveat, train-arriveby, train-leaveat, O\n","Intent are: book_hotel, book_hotel-book_restaurant, book_hotel-book_restaurant-find_taxi, book_hotel-book_train, book_hotel-find_attraction, book_hotel-find_attraction-find_restaurant, book_hotel-find_attraction-find_restaurant-find_train, book_hotel-find_attraction-find_taxi, book_hotel-find_hospital, book_hotel-find_restaurant, book_hotel-find_restaurant-find_taxi, book_hotel-find_taxi, book_hotel-find_train, book_restaurant, book_restaurant-book_train, book_restaurant-find_attraction, book_restaurant-find_attraction-find_hospital, book_restaurant-find_attraction-find_hotel, book_restaurant-find_attraction-find_taxi, book_restaurant-find_hospital, book_restaurant-find_hospital-find_taxi, book_restaurant-find_hotel, book_restaurant-find_hotel-find_taxi, book_restaurant-find_taxi, book_restaurant-find_taxi-find_train, book_restaurant-find_train, book_train, book_train-find_attraction, book_train-find_attraction-find_restaurant, book_train-find_bus, book_train-find_hotel, book_train-find_restaurant, book_train-find_taxi, find_attraction, find_attraction-find_hospital, find_attraction-find_hospital-find_hotel, find_attraction-find_hotel, find_attraction-find_hotel-find_restaurant, find_attraction-find_hotel-find_restaurant-find_taxi, find_attraction-find_hotel-find_taxi, find_attraction-find_hotel-find_train, find_attraction-find_police, find_attraction-find_restaurant, find_attraction-find_restaurant-find_taxi, find_attraction-find_restaurant-find_taxi-find_train, find_attraction-find_restaurant-find_train, find_attraction-find_taxi, find_attraction-find_taxi-find_train, find_attraction-find_train, find_bus-find_restaurant-find_train, find_bus-find_taxi-find_train, find_bus-find_train, find_hospital, find_hospital-find_hotel, find_hospital-find_hotel-find_restaurant, find_hospital-find_police, find_hospital-find_restaurant, find_hospital-find_restaurant-find_train, find_hospital-find_taxi, find_hospital-find_train, find_hotel, find_hotel-find_police, find_hotel-find_restaurant, find_hotel-find_restaurant-find_taxi, find_hotel-find_restaurant-find_train, find_hotel-find_taxi, find_hotel-find_train, find_police, find_police-find_restaurant, find_police-find_taxi, find_police-find_train, find_restaurant, find_restaurant-find_taxi, find_restaurant-find_taxi-find_train, find_restaurant-find_train, find_taxi, find_taxi-find_train, find_train\n","Domains are: attraction, attraction-hospital, attraction-hospital-hotel, attraction-hospital-restaurant, attraction-hotel, attraction-hotel-restaurant, attraction-hotel-restaurant-taxi, attraction-hotel-restaurant-train, attraction-hotel-taxi, attraction-hotel-train, attraction-police, attraction-restaurant, attraction-restaurant-taxi, attraction-restaurant-taxi-train, attraction-restaurant-train, attraction-taxi, attraction-taxi-train, attraction-train, bus-restaurant-train, bus-taxi-train, bus-train, hospital, hospital-hotel, hospital-hotel-restaurant, hospital-police, hospital-restaurant, hospital-restaurant-taxi, hospital-restaurant-train, hospital-taxi, hospital-train, hotel, hotel-police, hotel-restaurant, hotel-restaurant-taxi, hotel-restaurant-train, hotel-taxi, hotel-train, police, police-restaurant, police-taxi, police-train, restaurant, restaurant-taxi, restaurant-taxi-train, restaurant-train, taxi, taxi-train, train\n","Vocabulary size: 8245\n"]}],"source":["train_turns, train_slot_value_pairs, train_states, train_domains = get_slot_intent_domain(train_data)\n","dev_turns, dev_slot_value_pairs, dev_states, dev_domains = get_slot_intent_domain(dev_data)\n","test_turns, test_slot_value_pairs, test_states, test_domains = get_slot_intent_domain(test_data)\n","\n","all_slots = sorted(set([x for xs in train_slot_value_pairs + dev_slot_value_pairs + test_slot_value_pairs for x in xs]))\n","unique_states = sorted(set(train_states + dev_states + test_states))\n","unique_domains = sorted(set(train_domains + dev_domains + test_domains))\n","vocab = sorted(set([x for xs in train_turns + dev_turns + test_turns for x in xs]))\n","\n","unique_slots = []\n","for s in all_slots:\n","  if 'B-' == s[:2] or 'I-' == s[:2]:\n","    s = s[2:]\n","  if s not in unique_slots:\n","    unique_slots.append(s)\n","\n","print('\\nSlots are:', ', '.join(unique_slots))\n","print('Intent are:', ', '.join(unique_states))\n","print('Domains are:', ', '.join(unique_domains))\n","print('Vocabulary size:', len(vocab))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1678326335705,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"RHSGJA7RCooc","outputId":"223f0510-3fec-448f-ee4d-e360e2ce0f3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n","78\n","48\n"]}],"source":["print(len(unique_slots))\n","print(len(unique_states))\n","print(len(unique_domains))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThYKHPdZMPhS"},"outputs":[],"source":["# HW memory management\n","\n","del dev_turns, dev_slot_value_pairs, dev_states, dev_domains"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gh--svEGgLYa"},"outputs":[],"source":["# HW memory management\n","\n","del train_data, dev_data, test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1678326526189,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"OxQJ5wzCErKt","outputId":"7df14996-5274-4f85-e59a-53b4422e285b"},"outputs":[{"name":"stdout","output_type":"stream","text":["token:  ['6', 'people,', 'five', 'nights,', 'starting', 'on', 'thursday,', 'please.']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","intents:  find_hotel\n","domains:  hotel \n","\n","token:  ['yes', 'please', 'book', 'that.']\n","slot_labelled:  ['O', 'O', 'O', 'O']\n","intents:  book_hotel\n","domains:  hotel \n","\n","token:  [\"i'm\", 'sorry,', 'i', 'made', 'a', 'mistake!', 'i', 'need', 'for', 'it', 'to', 'start', 'on', 'tuesday', 'not', 'thursday!!!!', 'can', 'you', 'fix', 'that', 'for', 'me???']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","intents:  book_hotel\n","domains:  hotel \n","\n","token:  ['could', 'you', 'tell', 'me', 'whether', 'there', 'are', 'any', 'moderately', 'priced', 'catalan', 'restaurants?']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-restaurant-food', 'O']\n","intents:  find_restaurant\n","domains:  restaurant \n","\n","token:  ['yes', 'could', 'we', 'try', 'one', 'that', 'serves', 'british', 'food?']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-restaurant-food', 'O']\n","intents:  find_restaurant\n","domains:  restaurant \n","\n","token:  ['no', 'the', 'area', \"doesn't\", 'matter.', \"i'd\", 'like', 'to', 'book', 'a', 'table', 'for', '7', 'on', 'sunday.']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","intents:  book_restaurant-find_hotel\n","domains:  hotel-restaurant \n","\n","token:  ['ok,', 'book', 'that', 'place.']\n","slot_labelled:  ['O', 'O', 'O', 'O']\n","intents:  book_restaurant\n","domains:  restaurant \n","\n","token:  ['we', 'have', 'seven', 'people.']\n","slot_labelled:  ['O', 'O', 'O', 'O']\n","intents:  book_restaurant\n","domains:  restaurant \n","\n","token:  ['it', 'will', 'on', 'the', 'same', 'day', 'for', '3', 'nights.']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","intents:  find_hotel\n","domains:  hotel \n","\n","token:  [\"i'm\", 'sorry', 'i', \"didn't\", 'mean', 'to', 'confuse.', 'i', 'was', 'thinking', 'of', 'something', 'else.', 'can', 'i', 'book', 'the', 'oak', 'bistro', 'on', 'sunday', 'for', '7', 'people', 'at', '12:45?']\n","slot_labelled:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-restaurant-booktime']\n","intents:  book_restaurant-find_hotel-find_taxi\n","domains:  hotel-restaurant-taxi \n","\n"]}],"source":["i_begin = 4512\n","for i in range(i_begin, i_begin+10):\n","  print('token: ', train_turns[i])\n","  print('slot_labelled: ', train_slot_value_pairs[i])\n","  print('intents: ', train_states[i])\n","  print('domains: ', train_domains[i], '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4316,"status":"ok","timestamp":1678326535019,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"2Bwz_wvknUts","outputId":"89657785-aa9a-453b-9e87-1a310e85dc78"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'\u003cPAD\u003e': 0, 'B-attraction-name': 1, 'B-bus-departure': 2, 'B-bus-destination': 3, 'B-hospital-department': 4, 'B-hotel-name': 5, 'B-hotel-stars': 6, 'B-hotel-type': 7, 'B-restaurant-booktime': 8, 'B-restaurant-food': 9, 'B-restaurant-name': 10, 'B-taxi-arriveby': 11, 'B-taxi-departure': 12, 'B-taxi-destination': 13, 'B-taxi-leaveat': 14, 'B-train-arriveby': 15, 'B-train-leaveat': 16, 'I-attraction-name': 17, 'I-hospital-department': 18, 'I-hotel-name': 19, 'I-hotel-stars': 20, 'I-restaurant-booktime': 21, 'I-restaurant-food': 22, 'I-restaurant-name': 23, 'I-taxi-arriveby': 24, 'I-taxi-departure': 25, 'I-taxi-destination': 26, 'I-taxi-leaveat': 27, 'I-train-arriveby': 28, 'I-train-leaveat': 29, 'O': 30, '[CLS]': 31, '[SEP]': 32}\n","{'book_hotel': 0, 'book_hotel-book_restaurant': 1, 'book_hotel-book_restaurant-find_taxi': 2, 'book_hotel-book_train': 3, 'book_hotel-find_attraction': 4, 'book_hotel-find_attraction-find_restaurant': 5, 'book_hotel-find_attraction-find_restaurant-find_train': 6, 'book_hotel-find_attraction-find_taxi': 7, 'book_hotel-find_hospital': 8, 'book_hotel-find_restaurant': 9, 'book_hotel-find_restaurant-find_taxi': 10, 'book_hotel-find_taxi': 11, 'book_hotel-find_train': 12, 'book_restaurant': 13, 'book_restaurant-book_train': 14, 'book_restaurant-find_attraction': 15, 'book_restaurant-find_attraction-find_hospital': 16, 'book_restaurant-find_attraction-find_hotel': 17, 'book_restaurant-find_attraction-find_taxi': 18, 'book_restaurant-find_hospital': 19, 'book_restaurant-find_hospital-find_taxi': 20, 'book_restaurant-find_hotel': 21, 'book_restaurant-find_hotel-find_taxi': 22, 'book_restaurant-find_taxi': 23, 'book_restaurant-find_taxi-find_train': 24, 'book_restaurant-find_train': 25, 'book_train': 26, 'book_train-find_attraction': 27, 'book_train-find_attraction-find_restaurant': 28, 'book_train-find_bus': 29, 'book_train-find_hotel': 30, 'book_train-find_restaurant': 31, 'book_train-find_taxi': 32, 'find_attraction': 33, 'find_attraction-find_hospital': 34, 'find_attraction-find_hospital-find_hotel': 35, 'find_attraction-find_hotel': 36, 'find_attraction-find_hotel-find_restaurant': 37, 'find_attraction-find_hotel-find_restaurant-find_taxi': 38, 'find_attraction-find_hotel-find_taxi': 39, 'find_attraction-find_hotel-find_train': 40, 'find_attraction-find_police': 41, 'find_attraction-find_restaurant': 42, 'find_attraction-find_restaurant-find_taxi': 43, 'find_attraction-find_restaurant-find_taxi-find_train': 44, 'find_attraction-find_restaurant-find_train': 45, 'find_attraction-find_taxi': 46, 'find_attraction-find_taxi-find_train': 47, 'find_attraction-find_train': 48, 'find_bus-find_restaurant-find_train': 49, 'find_bus-find_taxi-find_train': 50, 'find_bus-find_train': 51, 'find_hospital': 52, 'find_hospital-find_hotel': 53, 'find_hospital-find_hotel-find_restaurant': 54, 'find_hospital-find_police': 55, 'find_hospital-find_restaurant': 56, 'find_hospital-find_restaurant-find_train': 57, 'find_hospital-find_taxi': 58, 'find_hospital-find_train': 59, 'find_hotel': 60, 'find_hotel-find_police': 61, 'find_hotel-find_restaurant': 62, 'find_hotel-find_restaurant-find_taxi': 63, 'find_hotel-find_restaurant-find_train': 64, 'find_hotel-find_taxi': 65, 'find_hotel-find_train': 66, 'find_police': 67, 'find_police-find_restaurant': 68, 'find_police-find_taxi': 69, 'find_police-find_train': 70, 'find_restaurant': 71, 'find_restaurant-find_taxi': 72, 'find_restaurant-find_taxi-find_train': 73, 'find_restaurant-find_train': 74, 'find_taxi': 75, 'find_taxi-find_train': 76, 'find_train': 77}\n","{'attraction': 0, 'attraction-hospital': 1, 'attraction-hospital-hotel': 2, 'attraction-hospital-restaurant': 3, 'attraction-hotel': 4, 'attraction-hotel-restaurant': 5, 'attraction-hotel-restaurant-taxi': 6, 'attraction-hotel-restaurant-train': 7, 'attraction-hotel-taxi': 8, 'attraction-hotel-train': 9, 'attraction-police': 10, 'attraction-restaurant': 11, 'attraction-restaurant-taxi': 12, 'attraction-restaurant-taxi-train': 13, 'attraction-restaurant-train': 14, 'attraction-taxi': 15, 'attraction-taxi-train': 16, 'attraction-train': 17, 'bus-restaurant-train': 18, 'bus-taxi-train': 19, 'bus-train': 20, 'hospital': 21, 'hospital-hotel': 22, 'hospital-hotel-restaurant': 23, 'hospital-police': 24, 'hospital-restaurant': 25, 'hospital-restaurant-taxi': 26, 'hospital-restaurant-train': 27, 'hospital-taxi': 28, 'hospital-train': 29, 'hotel': 30, 'hotel-police': 31, 'hotel-restaurant': 32, 'hotel-restaurant-taxi': 33, 'hotel-restaurant-train': 34, 'hotel-taxi': 35, 'hotel-train': 36, 'police': 37, 'police-restaurant': 38, 'police-taxi': 39, 'police-train': 40, 'restaurant': 41, 'restaurant-taxi': 42, 'restaurant-taxi-train': 43, 'restaurant-train': 44, 'taxi': 45, 'taxi-train': 46, 'train': 47}\n"]}],"source":["lEnc_slot = LabelEncoder()\n","lEnc_intent = LabelEncoder()\n","lEnc_domain = LabelEncoder()\n","unique_domains = np.array(unique_domains)\n","unique_intents=np.array(unique_states)\n","lEnc_slot.fit(np.array(['\u003cPAD\u003e'] + sorted(all_slots) +['[CLS]', '[SEP]']))\n","lEnc_intent.fit(unique_intents)\n","lEnc_domain.fit(unique_domains)\n","\n","integer_mapping_slot = {l: i for i, l in enumerate(lEnc_slot.classes_)}\n","integer_mapping_intent = {l: i for i, l in enumerate(lEnc_intent.classes_)}\n","integer_mapping_domain = {l: i for i, l in enumerate(lEnc_domain.classes_)}\n","print(integer_mapping_slot)\n","print(integer_mapping_intent)\n","print(integer_mapping_domain)\n","\n","train_slot_transformed=[]\n","test_slot_transformed=[]\n","\n","for seq_tr in train_slot_value_pairs:\n","  label=lEnc_slot.transform(seq_tr)\n","  train_slot_transformed.append(label)\n","\n","for seq_te in test_slot_value_pairs:\n","  label=lEnc_slot.transform(seq_te)\n","  test_slot_transformed.append(label)\n","\n","train_intent_transformed=lEnc_intent.transform(train_states)\n","test_intent_transformed=lEnc_intent.transform(test_states)\n","\n","train_domain_transformed=lEnc_domain.transform(train_domains)\n","test_domain_transformed=lEnc_domain.transform(test_domains)\n","pad_slot_id=integer_mapping_slot['\u003cPAD\u003e']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"my0IP-6WgsYq"},"outputs":[],"source":["# HW memory management\n","\n","del train_slot_value_pairs, test_slot_value_pairs"]},{"cell_type":"markdown","metadata":{"id":"1INz6riC3r2t"},"source":["##2.BERT embedding"]},{"cell_type":"markdown","metadata":{"id":"vqXabbS9rz1Z"},"source":["Code: https://colab.research.google.com/drive/1X1-vNm4N8JRfgLOxYUCeEQizQMvSCq1P?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfy9cZpAVFmo"},"outputs":[],"source":["# Authenticate\n","drive = None\n","def authenticate():\n","  global drive\n","\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  drive = GoogleDrive(gauth)\n","\n","\n","# Download files\n","def downloadFiles(fileIds):\n","  authenticate()\n","  for fileId in fileIds:\n","    downloaded = drive.CreateFile({\"id\": fileId[1]})\n","    downloaded.GetContentFile(fileId[0])\n","\n","downloadFiles([['train_bert_intent_embedding.h5','1USGeu6ZJ4rSDBNZ68k2h3AW58XGhMB2E'], ['test_bert_intent_embedding.h5','1-2N0Ue0DHnDrPDX3e88TldQp3IKlBbl4'],\n","               ['train_bert_slot_embedding.h5','1-5CoXFHS0hPlkaebHVwT46TNWwkjvRrq'], ['test_bert_slot_embedding.h5','1-EmXwhEjIsbJN4HSs7-0CGNbwAEJ5oMC'],\n","               ['train_bert_domain_embedding.h5','1-MyauTQdhhT-9vfYnwyMtrBIAGI895FQ'], ['test_bert_domain_embedding.h5','1-Q0V4FlS1YNMEDPp5nwg_XHbMz8GOLvq']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46730,"status":"ok","timestamp":1678089225264,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"rRMSaVE2d8Jj","outputId":"00d8b638-5b21-475c-ac0e-e8a4dce826a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(47897, 18, 768)\n","(6251, 18, 768)\n","(47897, 18, 768)\n","(6251, 18, 768)\n","(47897, 18, 768)\n","(6251, 18, 768)\n"]}],"source":["f=h5py.File('train_bert_intent_embedding.h5', 'r')\n","train_intent_bert=np.array(f[list(f.keys())[0]])\n","f=h5py.File('test_bert_intent_embedding.h5', 'r')\n","test_intent_bert=np.array(f[list(f.keys())[0]])\n","f=h5py.File('train_bert_slot_embedding.h5', 'r')\n","train_slot_bert=np.array(f[list(f.keys())[0]])\n","f=h5py.File('test_bert_slot_embedding.h5', 'r')\n","test_slot_bert=np.array(f[list(f.keys())[0]])\n","f=h5py.File('train_bert_domain_embedding.h5', 'r')\n","train_domain_bert=np.array(f[list(f.keys())[0]])\n","f=h5py.File('test_bert_domain_embedding.h5', 'r')\n","test_domain_bert=np.array(f[list(f.keys())[0]])\n","\n","f.close()\n","\n","print(train_slot_bert.shape)\n","print(test_slot_bert.shape)\n","print(train_intent_bert.shape)\n","print(test_intent_bert.shape)\n","print(train_domain_bert.shape)\n","print(test_domain_bert.shape)"]},{"cell_type":"markdown","metadata":{"id":"1wzyG3_2B152"},"source":["##3.Data processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21734,"status":"ok","timestamp":1678089246990,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"AEaTrHW9eWup","outputId":"f1b5e42c-83ea-4aaf-9c0d-99f49bdd4629"},"outputs":[{"name":"stdout","output_type":"stream","text":["['[CLS]', 'i', 'am', 'looking', 'for', 'a', 'train', 'leaving', 'from', 'ely', '.', '[SEP]']\n","['[CLS]', 'are', 'they', 'all', 'guest', '##houses', '?', '[SEP]']\n","[31, 30, 30, 30, 30, 30, 30, 30, 30, 30, 32]\n","[31, 30, 30, 30, 30, 32]\n"]}],"source":["# Tokenize with BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","train = [[\"[CLS]\"] + query + [\"[SEP]\"] for query in train_turns]\n","test = [[\"[CLS]\"] + query + [\"[SEP]\"] for query in test_turns]\n","train_mid=[]\n","for seq in train:\n","  words = [tokenizer.tokenize(w) for w in seq]\n","  this_sen = []\n","  for tokenized_parts in words:\n","    this_sen += tokenized_parts\n","  train_mid.append(this_sen)\n","test_mid=[]\n","for seq in test:\n","  words = [tokenizer.tokenize(w) for w in seq]\n","  this_sen = []\n","  for tokenized_parts in words:\n","    this_sen += tokenized_parts\n","  test_mid.append(this_sen)\n","\n","train_slot_mid = [[integer_mapping_slot['[CLS]']] + list(query) + [integer_mapping_slot['[SEP]']] for query in train_slot_transformed]\n","test_slot_mid = [[integer_mapping_slot['[CLS]']] + list(query) + [integer_mapping_slot['[SEP]']] for query in test_slot_transformed]\n","\n","id = 321\n","print(train_mid[id])\n","print(test_mid[id])\n","print(train_slot_mid[id])\n","print(test_slot_mid[id])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHTTZNfygDeO"},"outputs":[],"source":["train_max_turn_len = 18\n","test_max_turn_len = 18\n","# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","# Pad our input tokens\n","\n","vocab2inx={v:k for k,v in enumerate(vocab)}\n","train_seq_encoded=[[vocab2inx[w] for w in sent] for sent in train_turns]\n","test_seq_encoded=[[vocab2inx[w] for w in sent] for sent in test_turns]\n","\n","max_len=18\n","train_sequences_padded = pad_sequences(train_seq_encoded, maxlen=max_len, padding='post')\n","test_sequences_padded = pad_sequences(test_seq_encoded, maxlen=max_len, padding='post')\n","train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_mid],\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in test_mid],\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","train_slot_ids = pad_sequences(train_slot_mid,\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_slot_id)\n","test_slot_ids = pad_sequences(test_slot_mid,\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_slot_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cg24Y9PcgGBi"},"outputs":[],"source":["# Create attention masks\n","train_attention_masks = []\n","test_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in train_input_ids:\n","  seq_mask = [float(i\u003e0) for i in seq]\n","  train_attention_masks.append(seq_mask)\n","for seq in test_input_ids:\n","  seq_mask = [float(i\u003e0) for i in seq]\n","  test_attention_masks.append(seq_mask)\n","\n","# # Convert all of our data into torch tensors, the required datatype for our model\n","# train_inputs = torch.tensor(train_input_ids)\n","# test_inputs = torch.tensor(test_input_ids)\n","# train_labels = torch.tensor(train_intent_transformed)\n","# test_labels = torch.tensor(test_intent_transformed)\n","# train_slots = torch.tensor(train_slot_ids)\n","# test_slots = torch.tensor(test_slot_ids)\n","# train_masks = torch.tensor(train_attention_masks)\n","# test_masks = torch.tensor(test_attention_masks)\n","# train_labels_domain = torch.tensor(train_domain_transformed)\n","# test_labels_domain = torch.tensor(test_domain_transformed)\n","\n","# # Select a batch size for training.\n","# batch_size = 1024\n","\n","# # Create an iterator of our data with torch DataLoader\n","# train_data = TensorDataset(train_inputs, train_masks, train_labels, train_slots, train_labels_domain)\n","# train_sampler = RandomSampler(train_data)\n","# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# test_data = TensorDataset(test_inputs, test_masks, test_labels, test_slots, test_labels_domain)\n","# test_sampler = SequentialSampler(test_data)\n","# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","\n","# train_sampler_ = SequentialSampler(train_data)\n","# train_dataloader_ = DataLoader(train_data, sampler=train_sampler_, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bw0TAjMzgH2L"},"outputs":[],"source":["ind2slot={v:k for k,v in list(integer_mapping_slot.items())}\n","ind2intent={v:k for k,v in list(integer_mapping_intent.items())}\n","ind2domain={v:k for k,v in list(integer_mapping_domain.items())}\n","\n","slot_num = len(ind2slot)\n","intent_num = len(ind2intent)\n","domain_num = len(ind2domain)"]},{"cell_type":"markdown","metadata":{"id":"7FCBrUUuaCHP"},"source":["##4.Transformer encoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQ2kLHCGGg3a"},"outputs":[],"source":["def matmul(x):\n","    return tf.matmul(x[0], x[1])\n","\n","def split_heads(x, num_heads):\n","    x = keras.layers.Reshape((max_len, num_heads, -1))(x)\n","    return keras.layers.Permute((2,1,3))(x)\n","\n","def scaled_dot_product_attention(q, k, v, depth):\n","  matmul_qk = keras.layers.Lambda(matmul)([q,keras.layers.Permute((1,3,2))(k)])\n","  # scale matmul_qk\n","  scaled_attention_logits= keras.layers.Lambda(lambda x:x/math.sqrt(depth))(matmul_qk)\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores\n","  # add up to 1.\n","  attention_weights = keras.layers.Activation('softmax')(scaled_attention_logits)  # (..., seq_len_q, seq_len_k)\n","  output = keras.layers.Lambda(matmul)([attention_weights, v])\n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QCvvLRyHYR-"},"outputs":[],"source":["def trans(input_emb, d_model,num_heads,dff,dropout):\n","\n","  depth = d_model/num_heads\n","\n","  q = keras.layers.Dense(d_model)(input_emb)\n","  k = keras.layers.Dense(d_model)(input_emb)\n","  v = keras.layers.Dense(d_model)(input_emb)\n","\n","  qw = split_heads(q,num_heads)\n","  kw = split_heads(k,num_heads)\n","  vw = split_heads(v,num_heads)\n","\n","  scaled_attention = scaled_dot_product_attention(qw, kw, vw, depth)\n","  scaled_attention = keras.layers.Permute((2,1,3))(scaled_attention)\n","  concat_attention = keras.layers.Reshape((-1, d_model))(scaled_attention)\n","  concat_attention = keras.layers.Dense(d_model)(concat_attention)\n","  concat_attention = keras.layers.Dropout(dropout)(concat_attention)\n","  out_1 = LayerNormalization()(keras.layers.Add()([q,concat_attention]))\n","  ffn_output = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1))\n","  ffn_output = keras.layers.Dropout(dropout)(ffn_output)\n","  out_2 = LayerNormalization()(keras.layers.Add()([ffn_output,out_1]))\n","\n","  return out_2"]},{"cell_type":"markdown","metadata":{"id":"5uSlBh7ZGV0f"},"source":["### 4.1 Noex (Self-attention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ww87KnD7HSvD"},"outputs":[],"source":["###################\n","#####  noex   #####\n","###################\n","\n","\n","def new_trans_noex(input_slot_intent_domain,d_model,num_heads,dff,dropout):\n","  input_slot = input_slot_intent_domain[0]\n","  input_intent = input_slot_intent_domain[1]\n","  input_domain = input_slot_intent_domain[2]\n","  depth = d_model/num_heads\n","\n","  q_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  k_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  v_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  q_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  k_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  v_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  q_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  k_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  v_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","\n","  qw_slot_1 = split_heads(q_slot_1,num_heads)\n","  kw_slot_1 = split_heads(k_slot_1,num_heads)\n","  vw_slot_1 = split_heads(v_slot_1,num_heads)\n","\n","  qw_intent_1 = split_heads(q_intent_1,num_heads)\n","  kw_intent_1 = split_heads(k_intent_1,num_heads)\n","  vw_intent_1 = split_heads(v_intent_1,num_heads)\n","\n","  qw_domain_1 = split_heads(q_domain_1,num_heads)\n","  kw_domain_1 = split_heads(k_domain_1,num_heads)\n","  vw_domain_1 = split_heads(v_domain_1,num_heads)\n","\n","  scaled_attention_intent = scaled_dot_product_attention(qw_intent_1, kw_intent_1, vw_intent_1, depth)\n","  scaled_attention_intent = keras.layers.Permute((2,1,3))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Reshape((-1, d_model))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Dense(d_model)(concat_attention_intent)\n","  concat_attention_intent = keras.layers.Dropout(dropout)(concat_attention_intent)\n","  out_1_intent = LayerNormalization()(keras.layers.Add()([q_intent_1,concat_attention_intent]))\n","\n","  scaled_attention_domain = scaled_dot_product_attention(qw_domain_1, kw_domain_1, vw_domain_1, depth)\n","  scaled_attention_domain = keras.layers.Permute((2,1,3))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Reshape((-1, d_model))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Dense(d_model)(concat_attention_domain)\n","  concat_attention_domain = keras.layers.Dropout(dropout)(concat_attention_domain)\n","  out_1_domain = LayerNormalization()(keras.layers.Add()([q_domain_1,concat_attention_domain]))\n","\n","  scaled_attention_slot = scaled_dot_product_attention(qw_slot_1, kw_slot_1, vw_slot_1, depth)\n","  scaled_attention_slot = keras.layers.Permute((2,1,3))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Reshape((-1, d_model))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Dense(d_model)(concat_attention_slot)\n","  concat_attention_slot = keras.layers.Dropout(dropout)(concat_attention_slot)\n","  out_1_slot = LayerNormalization()(keras.layers.Add()([q_slot_1,concat_attention_slot]))\n","\n","  ffn_output_intent = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_intent))\n","  ffn_output_intent = keras.layers.Dropout(dropout)(ffn_output_intent)\n","  out_2_intent = LayerNormalization()(keras.layers.Add()([ffn_output_intent,out_1_intent]))\n","\n","  ffn_output_domain = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_domain))\n","  ffn_output_domain = keras.layers.Dropout(dropout)(ffn_output_domain)\n","  out_2_domain = LayerNormalization()(keras.layers.Add()([ffn_output_domain,out_1_domain]))\n","\n","  ffn_output_slot = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_slot))\n","  ffn_output_slot = keras.layers.Dropout(dropout)(ffn_output_slot)\n","  out_2_slot = LayerNormalization()(keras.layers.Add()([ffn_output_slot,out_1_slot]))\n","\n","  return out_2_slot,out_2_intent,out_2_domain"]},{"cell_type":"markdown","metadata":{"id":"EcKuh8hLGIbZ"},"source":["### 4.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1Q9TGj2GLi2"},"outputs":[],"source":["###################\n","#####  cross  #####\n","###################\n","\n","\n","def new_trans_cross(input_slot_intent_domain,d_model,num_heads,dff,dropout):\n","  input_slot = input_slot_intent_domain[0]\n","  input_intent = input_slot_intent_domain[1]\n","  input_domain = input_slot_intent_domain[2]\n","  depth = d_model/num_heads\n","\n","  q_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  k_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  v_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  q_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  k_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  v_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  q_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  k_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  v_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","\n","  qw_slot_1 = split_heads(q_slot_1,num_heads)\n","  kw_slot_1 = split_heads(k_slot_1,num_heads)\n","  vw_slot_1 = split_heads(v_slot_1,num_heads)\n","\n","  qw_intent_1 = split_heads(q_intent_1,num_heads)\n","  kw_intent_1 = split_heads(k_intent_1,num_heads)\n","  vw_intent_1 = split_heads(v_intent_1,num_heads)\n","\n","  qw_domain_1 = split_heads(q_domain_1,num_heads)\n","  kw_domain_1 = split_heads(k_domain_1,num_heads)\n","  vw_domain_1 = split_heads(v_domain_1,num_heads)\n","\n","  scaled_attention_intent = scaled_dot_product_attention(qw_intent_1, kw_slot_1, vw_slot_1, depth)\n","  scaled_attention_intent = keras.layers.Permute((2,1,3))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Reshape((-1, d_model))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Dense(d_model)(concat_attention_intent)\n","  concat_attention_intent = keras.layers.Dropout(dropout)(concat_attention_intent)\n","  out_1_intent = LayerNormalization()(keras.layers.Add()([q_intent_1,concat_attention_intent]))\n","\n","  scaled_attention_domain = scaled_dot_product_attention(qw_domain_1, kw_slot_1, vw_slot_1, depth)\n","  scaled_attention_domain = keras.layers.Permute((2,1,3))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Reshape((-1, d_model))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Dense(d_model)(concat_attention_domain)\n","  concat_attention_domain = keras.layers.Dropout(dropout)(concat_attention_domain)\n","  out_1_domain = LayerNormalization()(keras.layers.Add()([q_domain_1,concat_attention_domain]))\n","\n","  scaled_attention_slot = scaled_dot_product_attention(qw_slot_1, keras.layers.Dense(qw_slot_1.shape[-1])(tf.concat([kw_intent_1, kw_domain_1],-1)), keras.layers.Dense(qw_slot_1.shape[-1])(tf.concat([vw_intent_1, vw_domain_1],-1)), depth)\n","  scaled_attention_slot = keras.layers.Permute((2,1,3))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Reshape((-1, d_model))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Dense(d_model)(concat_attention_slot)\n","  concat_attention_slot = keras.layers.Dropout(dropout)(concat_attention_slot)\n","  out_1_slot = LayerNormalization()(keras.layers.Add()([q_slot_1,concat_attention_slot]))\n","\n","  ffn_output_intent = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_intent))\n","  ffn_output_intent = keras.layers.Dropout(dropout)(ffn_output_intent)\n","  out_2_intent = LayerNormalization()(keras.layers.Add()([ffn_output_intent,out_1_intent]))\n","\n","  ffn_output_domain = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_domain))\n","  ffn_output_domain = keras.layers.Dropout(dropout)(ffn_output_domain)\n","  out_2_domain = LayerNormalization()(keras.layers.Add()([ffn_output_domain,out_1_domain]))\n","\n","  ffn_output_slot = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_slot))\n","  ffn_output_slot = keras.layers.Dropout(dropout)(ffn_output_slot)\n","  out_2_slot = LayerNormalization()(keras.layers.Add()([ffn_output_slot,out_1_slot]))\n","\n","  return out_2_slot,out_2_intent,out_2_domain"]},{"cell_type":"markdown","metadata":{"id":"o080_1ziGD7H"},"source":["### 4.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlVL1LwPIWlx"},"outputs":[],"source":["###################\n","#####   bf    #####\n","###################\n","\n","\n","def new_trans_bf(input_slot_intent_domain,d_model,num_heads,dff,dropout):\n","  input_slot = input_slot_intent_domain[0]\n","  input_intent = input_slot_intent_domain[1]\n","  input_domain = input_slot_intent_domain[2]\n","  depth = d_model/num_heads\n","\n","  q_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  k_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  v_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  q_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  k_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  v_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  q_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  k_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  v_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","\n","  qw_slot_1 = split_heads(q_slot_1,num_heads)\n","  kw_slot_1 = split_heads(k_slot_1,num_heads)\n","  vw_slot_1 = split_heads(v_slot_1,num_heads)\n","\n","  qw_intent_1 = split_heads(q_intent_1,num_heads)\n","  kw_intent_1 = split_heads(k_intent_1,num_heads)\n","  vw_intent_1 = split_heads(v_intent_1,num_heads)\n","\n","  qw_domain_1 = split_heads(q_domain_1,num_heads)\n","  kw_domain_1 = split_heads(k_domain_1,num_heads)\n","  vw_domain_1 = split_heads(v_domain_1,num_heads)\n","\n","  scaled_attention_intent = scaled_dot_product_attention(qw_intent_1, kw_intent_1, vw_intent_1, depth)\n","  scaled_attention_intent = keras.layers.Permute((2,1,3))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Reshape((-1, d_model))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Dense(d_model)(concat_attention_intent)\n","  concat_attention_intent = keras.layers.Dropout(dropout)(concat_attention_intent)\n","  out_1_intent = LayerNormalization()(keras.layers.Add()([q_intent_1,concat_attention_intent]))\n","\n","  scaled_attention_domain = scaled_dot_product_attention(qw_domain_1, kw_domain_1, vw_domain_1, depth)\n","  scaled_attention_domain = keras.layers.Permute((2,1,3))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Reshape((-1, d_model))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Dense(d_model)(concat_attention_domain)\n","  concat_attention_domain = keras.layers.Dropout(dropout)(concat_attention_domain)\n","  out_1_domain = LayerNormalization()(keras.layers.Add()([q_domain_1,concat_attention_domain]))\n","\n","  scaled_attention_slot = scaled_dot_product_attention(qw_slot_1, kw_slot_1, vw_slot_1, depth)\n","  scaled_attention_slot = keras.layers.Permute((2,1,3))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Reshape((-1, d_model))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Dense(d_model)(concat_attention_slot)\n","  concat_attention_slot = keras.layers.Dropout(dropout)(concat_attention_slot)\n","  out_1_slot = LayerNormalization()(keras.layers.Add()([q_slot_1,concat_attention_slot]))\n","\n","  ffn_output_intent = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_slot))\n","  ffn_output_intent = keras.layers.Dropout(dropout)(ffn_output_intent)\n","  out_2_intent = LayerNormalization()(keras.layers.Add()([ffn_output_intent,out_1_intent]))\n","\n","  ffn_output_domain = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_slot))\n","  ffn_output_domain = keras.layers.Dropout(dropout)(ffn_output_domain)\n","  out_2_domain = LayerNormalization()(keras.layers.Add()([ffn_output_domain,out_1_domain]))\n","\n","  ffn_output_slot = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(keras.layers.Dense(out_1_slot.shape[-1])(tf.concat([out_1_intent, out_1_domain], -1))))\n","  ffn_output_slot = keras.layers.Dropout(dropout)(ffn_output_slot)\n","  out_2_slot = LayerNormalization()(keras.layers.Add()([ffn_output_slot,out_1_slot]))\n","\n","  return out_2_slot,out_2_intent,out_2_domain"]},{"cell_type":"markdown","metadata":{"id":"-bWG3mZxGN2f"},"source":["### 4.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtsY1DNeGRWw"},"outputs":[],"source":["###################\n","#####   af    #####\n","###################\n","\n","\n","def new_trans_af(input_slot_intent_domain,d_model,num_heads,dff,dropout):\n","  input_slot = input_slot_intent_domain[0]\n","  input_intent = input_slot_intent_domain[1]\n","  input_domain = input_slot_intent_domain[2]\n","  depth = d_model/num_heads\n","\n","  q_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  k_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  v_slot_1 = keras.layers.Dense(d_model)(input_slot)\n","  q_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  k_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  v_intent_1 = keras.layers.Dense(d_model)(input_intent)\n","  q_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  k_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","  v_domain_1 = keras.layers.Dense(d_model)(input_domain)\n","\n","  qw_slot_1 = split_heads(q_slot_1,num_heads)\n","  kw_slot_1 = split_heads(k_slot_1,num_heads)\n","  vw_slot_1 = split_heads(v_slot_1,num_heads)\n","\n","  qw_intent_1 = split_heads(q_intent_1,num_heads)\n","  kw_intent_1 = split_heads(k_intent_1,num_heads)\n","  vw_intent_1 = split_heads(v_intent_1,num_heads)\n","\n","  qw_domain_1 = split_heads(q_domain_1,num_heads)\n","  kw_domain_1 = split_heads(k_domain_1,num_heads)\n","  vw_domain_1 = split_heads(v_domain_1,num_heads)\n","\n","  scaled_attention_intent = scaled_dot_product_attention(qw_intent_1, kw_intent_1, vw_intent_1, depth)\n","  scaled_attention_intent = keras.layers.Permute((2,1,3))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Reshape((-1, d_model))(scaled_attention_intent)\n","  concat_attention_intent = keras.layers.Dense(d_model)(concat_attention_intent)\n","  concat_attention_intent = keras.layers.Dropout(dropout)(concat_attention_intent)\n","  out_1_intent = LayerNormalization()(keras.layers.Add()([q_intent_1,concat_attention_intent]))\n","\n","  scaled_attention_domain = scaled_dot_product_attention(qw_domain_1, kw_domain_1, vw_domain_1, depth)\n","  scaled_attention_domain = keras.layers.Permute((2,1,3))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Reshape((-1, d_model))(scaled_attention_domain)\n","  concat_attention_domain = keras.layers.Dense(d_model)(concat_attention_domain)\n","  concat_attention_domain = keras.layers.Dropout(dropout)(concat_attention_domain)\n","  out_1_domain = LayerNormalization()(keras.layers.Add()([q_domain_1,concat_attention_domain]))\n","\n","  scaled_attention_slot = scaled_dot_product_attention(qw_slot_1, kw_slot_1, vw_slot_1, depth)\n","  scaled_attention_slot = keras.layers.Permute((2,1,3))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Reshape((-1, d_model))(scaled_attention_slot)\n","  concat_attention_slot = keras.layers.Dense(d_model)(concat_attention_slot)\n","  concat_attention_slot = keras.layers.Dropout(dropout)(concat_attention_slot)\n","  out_1_slot = LayerNormalization()(keras.layers.Add()([q_slot_1,concat_attention_slot]))\n","\n","  ffn_output_intent = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_intent))\n","  ffn_output_intent = keras.layers.Dropout(dropout)(ffn_output_intent)\n","\n","  ffn_output_slot = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_slot))\n","  ffn_output_slot = keras.layers.Dropout(dropout)(ffn_output_slot)\n","\n","  ffn_output_domain = keras.layers.Dense(d_model)(keras.layers.Dense(dff, activation='relu')(out_1_domain))\n","  ffn_output_domain = keras.layers.Dropout(dropout)(ffn_output_domain)\n","\n","  out_2_intent = LayerNormalization()(keras.layers.Add()([ffn_output_slot,out_1_intent]))\n","  out_2_domain = LayerNormalization()(keras.layers.Add()([ffn_output_slot,out_1_domain]))\n","  out_2_slot = LayerNormalization()(keras.layers.Add()([keras.layers.Dense(ffn_output_slot.shape[-1])(tf.concat([ffn_output_intent, ffn_output_domain], -1)),out_1_slot]))\n","\n","  return out_2_slot,out_2_intent,out_2_domain"]},{"cell_type":"markdown","metadata":{"id":"HoBCnYbzGzvQ"},"source":["## 5.Get Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Os8bNlXH3esT"},"outputs":[],"source":["# without bi-directional\n","def get_model_by_encoder_num(model='cross', encoder_num=1):\n","  input_slot=keras.layers.Input(shape=(max_len,768), name='Slot-Embed')\n","  input_intent=keras.layers.Input(shape=(max_len,768), name='Intent-Embed')\n","  input_domain=keras.layers.Input(shape=(max_len,768), name='Domain-Embed')\n","\n","  if model=='noex':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_noex([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_noex([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='cross':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_cross([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_cross([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='bf':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_bf([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_bf([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='af':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_af([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_af([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","\n","  slot_out_2 = keras.layers.Dropout(0.1)(slot_out_2)\n","  intent_out_2 = keras.layers.Dropout(0.1)(intent_out_2)\n","  domain_out_2 = keras.layers.Dropout(0.1)(domain_out_2)\n","\n","  intent_out_logits=keras.layers.Flatten()(intent_out_2)\n","  intent_out_logits=keras.layers.Dense(intent_num, activation=\"softmax\", name=\"intent_output\")(intent_out_logits)\n","  domain_out_logits=keras.layers.Flatten()(domain_out_2)\n","  domain_out_logits=keras.layers.Dense(domain_num, activation=\"softmax\", name=\"domain_output\")(domain_out_logits)\n","  slot_out_logits= keras.layers.TimeDistributed(keras.layers.Dense(slot_num, activation=\"softmax\"), \\\n","                                                input_shape=(max_len, slot_out_2.shape[-1]), name=\"slot_output\")(slot_out_2)\n","\n","  return keras.models.Model(inputs=[input_slot, input_intent, input_domain], outputs=[slot_out_logits, intent_out_logits, domain_out_logits])\n","\n","# with bi-directional\n","def get_model_bidir_by_encoder_num(model='cross', encoder_num=1):\n","  input_slot=keras.layers.Input(shape=(max_len,768), name='Slot-Embed')\n","  input_intent=keras.layers.Input(shape=(max_len,768), name='Intent-Embed')\n","  input_domain=keras.layers.Input(shape=(max_len,768), name='Domain-Embed')\n","\n","  if model=='noex':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_noex([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_noex([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='cross':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_cross([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_cross([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='bf':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_bf([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_bf([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","  if model=='af':\n","    slot_out_2, intent_out_2, domain_out_2 = new_trans_af([input_slot,input_intent,input_domain],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","    for i in range(encoder_num-1):\n","      slot_out_2, intent_out_2, domain_out_2 = new_trans_af([slot_out_2,intent_out_2,domain_out_2],d_model=768, num_heads=3, dff = 1296, dropout=0.5)\n","\n","  slot_out_2 = keras.layers.Dropout(0.1)(slot_out_2)\n","  intent_out_2 = keras.layers.Dropout(0.1)(intent_out_2)\n","  domain_out_2 = keras.layers.Dropout(0.1)(domain_out_2)\n","\n","  intent_out_flatten = keras.layers.Flatten()(intent_out_2)\n","  intent_out_dense = keras.layers.Dense(1, activation=\"tanh\")(intent_out_flatten)\n","  intent_out_logits=keras.layers.Dense(intent_num, activation=\"softmax\", name=\"intent_encoder_output\")(intent_out_dense)\n","\n","  domain_out_flatten = keras.layers.Flatten()(domain_out_2)\n","  domain_out_dense = keras.layers.Dense(1, activation=\"tanh\")(domain_out_flatten)\n","  domain_out_logits=keras.layers.Dense(domain_num, activation=\"softmax\", name=\"domain_encoder_output\")(domain_out_dense)\n","\n","\n","  slot_out_logits= keras.layers.TimeDistributed(keras.layers.Dense(slot_num, activation=\"softmax\"), input_shape=(max_len, slot_out_2.shape[-1]), name=\"slot_encoder_output\")(slot_out_2)\n","\n","  # slot gate\n","  intent_out_repeat = keras.layers.RepeatVector(max_len)(intent_out_logits)\n","  domain_out_repeat = keras.layers.RepeatVector(max_len)(domain_out_logits)\n","  slot_gate = keras.layers.Concatenate(axis=-1)([slot_out_2,intent_out_repeat,domain_out_repeat])\n","  slot_gate_logits = keras.layers.TimeDistributed(keras.layers.Dense(slot_num, activation=\"softmax\"), input_shape=(max_len, slot_gate.shape[-1]), name=\"slot_output\")(slot_gate)\n","\n","  # intent gate\n","  slot_out_flatten =  keras.layers.Flatten()(slot_out_2) # CHANGED\n","  intent_gate = keras.layers.Concatenate(axis=-1)([intent_out_dense, slot_out_flatten, domain_out_dense])\n","  intent_gate_logits=keras.layers.Dense(intent_num, activation=\"softmax\", name=\"intent_output\")(intent_gate)\n","\n","  # intent gate\n","  slot_out_flatten =  keras.layers.Flatten()(slot_out_2) # CHANGED\n","  domain_gate = keras.layers.Concatenate(axis=-1)([domain_out_dense, intent_out_dense, slot_out_flatten])\n","  domain_gate_logits=keras.layers.Dense(domain_num, activation=\"softmax\", name=\"domain_output\")(domain_gate)\n","\n","  return keras.models.Model(inputs=[input_slot, input_intent, input_domain], outputs=[slot_gate_logits, intent_gate_logits, domain_gate_logits])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xjDQZ3-mXEn"},"outputs":[],"source":["# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","# Pad our input tokens\n","train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_mid],\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in test_mid],\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","train_slot_ids = pad_sequences(train_slot_mid,\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_slot_id)\n","test_slot_ids = pad_sequences(test_slot_mid,\n","                          maxlen=18, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_slot_id)\n","\n","# Create attention masks\n","train_attention_masks = []\n","test_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in train_input_ids:\n","  seq_mask = [float(i\u003e0) for i in seq]\n","  train_attention_masks.append(seq_mask)\n","for seq in test_input_ids:\n","  seq_mask = [float(i\u003e0) for i in seq]\n","  test_attention_masks.append(seq_mask)\n","\n","# # Convert all of our data into torch tensors, the required datatype for our model\n","# train_inputs = torch.tensor(train_input_ids)\n","# test_inputs = torch.tensor(test_input_ids)\n","# train_intents = torch.tensor(train_intent_transformed)\n","# test_intents = torch.tensor(test_intent_transformed)\n","# train_slots = torch.tensor(train_slot_ids)\n","# test_slots = torch.tensor(test_slot_ids)\n","# train_masks = torch.tensor(train_attention_masks)\n","# test_masks = torch.tensor(test_attention_masks)\n","# train_domains = torch.tensor(train_domain_transformed)\n","# test_domains = torch.tensor(test_domain_transformed)\n","\n","# # Select a batch size for training.\n","# batch_size = 1024\n","\n","# # Create an iterator of our data with torch DataLoader\n","# train_data = TensorDataset(train_inputs, train_masks, train_slots, train_intents, train_domains)\n","# train_sampler = RandomSampler(train_data)\n","# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# test_data = TensorDataset(test_inputs, test_masks, test_slots, test_intents, test_domains)\n","# test_sampler = SequentialSampler(test_data)\n","# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95XK9Jqn_Cqr"},"outputs":[],"source":["def process_mask(mask_in_batch):\n","  for i,mask in enumerate(mask_in_batch):\n","    sep_index=int(mask.sum()-1)\n","    mask_in_batch[i][0]=0\n","    mask_in_batch[i][sep_index]=0\n","  return mask_in_batch"]},{"cell_type":"markdown","metadata":{"id":"aEn_6vHc3jKV"},"source":["##6.Evaluation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EH04bQDI7oPC"},"outputs":[],"source":["def evaluate(trans_model, slot_X_train, slot_X_test, intent_X_train, intent_X_test, domain_X_train, domain_X_test, slot_y_train, slot_y_test, intent_y_train, intent_y_test, domain_y_train, domain_y_test, batch_size=8, epoch=10, learningRate=0.001):\n","\n","  learningRate=learningRate\n","\n","  losses = {\n","\t\"slot_output\": \"sparse_categorical_crossentropy\",\n","\t\"intent_output\": \"sparse_categorical_crossentropy\",\n","  \"domain_output\": \"sparse_categorical_crossentropy\",\n","  }\n","\n","  lossWeights = {\"slot_output\": 1.0, \"intent_output\": 1.0, \"domain_output\": 1.0}\n","\n","  trans_model.compile(\n","      optimizer= Adam(learningRate),\n","      loss=losses,\n","      loss_weights=lossWeights,\n","      metrics = [\"accuracy\"]\n","  )\n","\n","\n","  # trans_model.summary()\n","\n","  current_time = datetime.now()\n","  trans_model.fit([slot_X_train, intent_X_train, domain_X_train], [slot_y_train, intent_y_train, domain_y_train], batch_size=batch_size, epochs=epoch)\n","  train_time=datetime.now() - current_time\n","  print(\"Training took time: \", train_time)\n","\n","\n","  # Evaluate model\n","\n","  scores = trans_model.evaluate([slot_X_train, intent_X_train, domain_X_train], [slot_y_train, intent_y_train, domain_y_train], batch_size = batch_size, verbose = 0)\n","  train_acc=(scores[-1]+scores[-2])/2\n","  print(\"Training accuracy: \",train_acc)\n","\n","\n","  current_time = datetime.now()\n","  scores = trans_model.evaluate([slot_X_test, intent_X_test, domain_X_test], [slot_y_test, intent_y_test, domain_y_test], batch_size = batch_size, verbose = 0)\n","  eval_time=datetime.now() - current_time\n","  print(\"Evaluation took time: \", eval_time)\n","  eval_acc=(scores[-1]+scores[-2])/2\n","  print(\"Evaluation accuracy: \",eval_acc)\n","\n","  # Predict classes\n","  preds = trans_model.predict([slot_X_test, intent_X_test, domain_X_test], batch_size = batch_size)\n","\n","  return train_acc, eval_acc, train_time, eval_time, slot_y_test, intent_y_test, \\\n","  domain_y_test, np.argmax(preds[0], axis=-1), np.argmax(preds[1], axis=-1), np.argmax(preds[2], axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bL0pc-OSWty6"},"outputs":[],"source":["ind2slot={v:k for k,v in list(integer_mapping_slot.items())}\n","ind2intent={v:k for k,v in list(integer_mapping_intent.items())}\n","ind2domain={v:k for k,v in list(integer_mapping_domain.items())}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVovdUexrotR"},"outputs":[],"source":["# calculate sentence senmantic\n","def sentence_senm(correct_intents, pred_intents, correct_slots, slot_outputs, correct_domains, pred_domains):\n","  if(type(pred_intents[0]) is np.ndarray):\n","    pred_intents=[x[0] for x in pred_intents]\n","  correct_intents=np.array(correct_intents)\n","  pred_intents=np.array(pred_intents)\n","\n","  if(type(pred_domains[0]) is np.ndarray):\n","    pred_domains=[x[0] for x in pred_domains]\n","  correct_domains=np.array(correct_domains)\n","  pred_domains=np.array(pred_domains)\n","\n","  semantic_error = (pred_intents==correct_intents)\n","\n","  slot_outputs_origin=[]\n","  correct_slots_origin=[]\n","\n","  for s_out, s_cor in zip (slot_outputs,correct_slots):\n","    if type(s_out[0])==list:\n","      new_seq_true= [x for x in s_cor]\n","    else:\n","      new_seq_true=s_cor\n","\n","    new_seq_true=np.trim_zeros(new_seq_true)\n","    correct_slots_origin.append(new_seq_true)\n","    new_seq_temp= s_out[:len(new_seq_true)]\n","\n","    slot_outputs_origin.append(new_seq_temp)\n","\n","  index=0\n","\n","  for t,p in zip(correct_slots_origin, slot_outputs_origin):\n","    assert len(t)==len(p)\n","\n","    for j in range(len(t)):\n","      if p[j] != t[j]:\n","        semantic_error[index]=False\n","\n","        break\n","    index+=1\n","\n","  semantic_error=semantic_error.astype(float)\n","  semantic_error=np.mean(semantic_error)*100.0\n","\n","  return semantic_error\n","\n","\n","\n","def print_semantic(correct_intents, pred_intents, correct_slots, slot_outputs, correct_domains, pred_domains, test_seq):\n","  if(type(pred_intents[0]) is np.ndarray):\n","    pred_intents=[x[0] for x in pred_intents]\n","  if(type(pred_domains[0]) is np.ndarray):\n","    pred_domainss=[x[0] for x in pred_domains]\n","\n","\n","  #slot_outputs_origin=[]\n","  #correct_slots_origin=[]\n","\n","  count=1\n","  for s_out, s_cor, i_out, i_cor, d_out, d_cor, seq in \\\n","  zip (slot_outputs,correct_slots, pred_intents, correct_intents, pred_domains, correct_domains, test_seq):\n","\n","    #print()\n","    if type(s_out[0])==list:\n","      new_seq_true= [x for x in s_cor]\n","    else:\n","      new_seq_true=s_cor\n","\n","\n","    new_seq_true=np.trim_zeros(new_seq_true)\n","    #correct_slots_origin.append(new_seq_true)\n","    new_seq_temp= s_out[:len(new_seq_true)]\n","    new_seq_true=[ind2slot[x] for x in new_seq_true]\n","    new_seq_temp=[ind2slot[x] for x in new_seq_temp]\n","    print_checker=True\n","    for w1,w2 in zip(new_seq_true, new_seq_temp):\n","      if w1!=w2:\n","        print_checker=False\n","        break\n","    if print_checker and i_out!=i_cor:\n","      count+=1\n","      print(\"#\"*120)\n","      print(\"[\", str(count),\"][WRONG] \", ind2intent[i_out], \"=\u003e\",ind2intent[i_cor])\n","      print(seq)\n","      print(new_seq_true)\n","      print(new_seq_temp)\n","      #slot_outputs_origin.append(new_seq_temp)\n","\n","      #print()\n","    if not print_checker:\n","      count+=1\n","      print(\"#\"*120)\n","      if i_out==i_cor:\n","        print(\"[\", str(count),\"][CORRECT] \", ind2intent[i_cor])\n","      else:\n","        print(\"[\", str(count),\"][WRONG] \", ind2intent[i_out], \"=\u003e\",ind2intent[i_cor])\n","      print(seq)\n","      print(new_seq_true)\n","      print(new_seq_temp)\n","\n","  print(\"#\"*120)\n","\n","def intent_f1_each_class(y_true, y_pred):\n","\n","  return f_score(y_true, y_pred, labels=list(np.unique(np.array(y_true))), average=None)\n","\n","\n","#calculate accuracy for intent classificaiton\n","def intent_accuracy(y_true, y_pred):\n","  correct_cnt=0\n","  for i,intent in enumerate(y_true):\n","    if intent==y_pred[i]:\n","      correct_cnt+=1\n","  return correct_cnt/len(y_true)\n","\n","\n","#calculate the precision, recall, f1 for slot filling\n","def slot_accuracy(y_true, y_pred):\n","  new_y_true=[]\n","  new_y_pred=[]\n","\n","\n","  for se, pre in zip(y_true, y_pred):\n","\n","    new_seq_true=np.trim_zeros(se)\n","    #print(new_seq_true)\n","    new_y_true.extend(list(new_seq_true))\n","    #print(new_seq_true)\n","\n","\n","    if (type(pre[0])==list):\n","      pre=[x[0] for x in pre]\n","    new_seq_temp= list(pre)[:len(new_seq_true)]\n","    #print(new_seq_temp)\n","    #print()\n","    new_y_pred.extend(new_seq_temp)\n","  #print(new_y_true)\n","  label=list(set(new_y_true))\n","\n","  correct=0\n","  for i,j in zip(new_y_true, new_y_pred):\n","    if (i==j):\n","      correct+=1\n","  accuracy=correct/len(new_y_true)\n","\n","  return accuracy,pre_score(new_y_true, new_y_pred, labels=label, average='micro'), \\\n","  re_score(new_y_true, new_y_pred, labels=label, average='micro'), \\\n","  f_score(new_y_true, new_y_pred, labels=label, average='micro')\n","\n","\n","def slot_accuracy_slot_based(y_true, y_pred):\n","  new_y_true=[]\n","  new_y_pred=[]\n","  for se, pre in zip(y_true, y_pred):\n","    #new_seq_true= [x for x in se]\n","    new_seq_true= se\n","    new_seq_true=np.trim_zeros(new_seq_true)\n","    #new_seq_true_slot=[list(tag_to_ix.keys())[list(tag_to_ix.values()).index(x)] for x in new_seq_true]\n","    #new_y_true.extend(new_seq_true_slot)\n","    new_y_true.extend(new_seq_true)\n","    new_seq_temp= pre[:len(new_seq_true)]\n","    #new_seq_pre_slot=[list(tag_to_ix.keys())[list(tag_to_ix.values()).index(x)] for x in new_seq_temp]\n","    #new_y_pred.extend(new_seq_pre_slot)\n","    new_y_pred.extend(new_seq_temp)\n","  #print(\"####\")\n","  #print(len(new_y_true))\n","  #print(new_y_true)\n","  #print()\n","  #print(len(new_y_pred))\n","\n","  #print(new_y_pred)\n","  new_y_true=[[ind2slot[x] for x in new_y_true]]\n","  new_y_pred=[[ind2slot[x] for x in new_y_pred]]\n","\n","  y_accuracy = accuracy_score(new_y_true[0],new_y_pred[0])\n","  y_f1 = f1_score(new_y_true,new_y_pred)\n","  y_precison = precision_score(new_y_true,new_y_pred)\n","  y_recall = recall_score(new_y_true,new_y_pred)\n","  print(seqeval_classification_report(new_y_true,new_y_pred))\n","\n","  return pd.DataFrame(seqeval_classification_report(new_y_true,new_y_pred,output_dict=True)).iloc[:-1, :].T, y_accuracy,y_precison,y_recall,y_f1\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HCWIhPfQuo4"},"outputs":[],"source":["from google.colab import files\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","from tabulate import tabulate\n","import warnings\n","import pandas as pd\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","def plotConfusionMatrix(cmArray, labels, title, download=False):\n","  df_cm = pd.DataFrame(cmArray, index = [i for i in labels],\n","                    columns = [i for i in labels])\n","\n","  plt.figure(figsize = (5,4))\n","  #plt.title(title)\n","  sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\", fmt='g')\n","  if (download):\n","    plt.savefig(title)\n","    files.download(title+\".png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1678089331767,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"Dvhnsdo_uPQq","outputId":"89dcea42-4159-4194-d7b6-d5f3214cd78f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(47897, 18)\n","(6251, 18)\n","(47897, 18)\n","(6251, 18)\n","(47897,)\n","(6251,)\n","(47897,)\n","(6251,)\n","33\n","78\n","48\n"]}],"source":["train_slot_padded = pad_sequences(train_slot_transformed, maxlen=max_len, padding='post')\n","test_slot_padded = pad_sequences(test_slot_transformed, maxlen=max_len, padding='post')\n","\n","#HW memory management\n","del train_slot_transformed, test_slot_transformed\n","\n","train_slot_padded=np.array(train_slot_padded)\n","test_slot_padded=np.array(test_slot_padded)\n","train_intent_transformed=np.array(train_intent_transformed)\n","test_intent_transformed=np.array(test_intent_transformed)\n","train_domain_transformed=np.array(train_domain_transformed)\n","test_domain_transformed=np.array(test_domain_transformed)\n","print(train_sequences_padded.shape)\n","print(test_sequences_padded.shape)\n","print(train_slot_padded.shape)\n","print(test_slot_padded.shape)\n","print(train_intent_transformed.shape)\n","print(test_intent_transformed.shape)\n","print(train_domain_transformed.shape)\n","print(test_domain_transformed.shape)\n","\n","slot_num=len(integer_mapping_slot)\n","intent_num=len(integer_mapping_intent)\n","domain_num=len(integer_mapping_domain)\n","print(slot_num)\n","print(intent_num)\n","print(domain_num)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1059,"status":"ok","timestamp":1678089336651,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"DMDlvcyt3Uhf","outputId":"b747b017-4c6f-400d-be34-da806c3346b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["(47897, 18)\n","(6251, 18)\n","(47897, 18)\n","(6251, 18)\n","(47897,)\n","(6251,)\n","(47897, 18, 768)\n","(6251, 18, 768)\n","(47897, 18, 768)\n","(6251, 18, 768)\n","(47897, 18, 768)\n","(6251, 18, 768)\n"]}],"source":["print(train_sequences_padded.shape)\n","print(test_sequences_padded.shape)\n","print(train_slot_padded.shape)\n","print(test_slot_padded.shape)\n","print(train_intent_transformed.shape)\n","print(test_intent_transformed.shape)\n","\n","print(train_slot_bert.shape)\n","print(test_slot_bert.shape)\n","print(train_intent_bert.shape)\n","print(test_intent_bert.shape)\n","print(train_domain_bert.shape)\n","print(test_domain_bert.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwh33-g2vEtn"},"outputs":[],"source":["slot_accs = []\n","intent_accs = []\n","domain_accs = []\n","\n","model_names = ['Noex', 'Cross', 'BF', 'AF']"]},{"cell_type":"markdown","metadata":{"id":"XZd3ZYVwyjF1"},"source":["#7.Without bi-dir"]},{"cell_type":"markdown","metadata":{"id":"bz5fNJBuY9cw"},"source":["## 7.1 epoch = 5, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"3lEBO57zZZz3"},"source":["### 7.1.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlu00xRgwsBS"},"outputs":[],"source":["unique_slots = np.array(['\u003cPAD\u003e'] + unique_slots)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsYhDW8Qqr67"},"outputs":[],"source":["#without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed), np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.1.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.1.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.1.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JFTJZRipZF0"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.1.1')"]},{"cell_type":"markdown","metadata":{"id":"PbhFBxWscEvL"},"source":["### 7.1.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-KX6yDQyQEQ"},"outputs":[],"source":["#without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.1.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.1.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.1.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opdT15TMpkcK"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.1.2')"]},{"cell_type":"markdown","metadata":{"id":"fGCDbiaXcpBC"},"source":["### 7.1.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGIUy7SacrON"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.1.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.1.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.1.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qj-9vQQXpmEE"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.1.3')"]},{"cell_type":"markdown","metadata":{"id":"Nz8CZxEvcvqa"},"source":["### 7.1.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxHIU1NSctnq"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.1.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.1.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.1.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nur_4Jv9pn7Y"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.1.4')"]},{"cell_type":"markdown","metadata":{"id":"1tYyr3jNZbC_"},"source":["## 7.2 epoch = 10, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"zuOVLqDTZlKI"},"source":["### 7.2.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h213ls2dZhsx"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.2.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.2.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.2.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9R-sy34ppzd"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.2.1')"]},{"cell_type":"markdown","metadata":{"id":"GWXCzX0cZn4G"},"source":["### 7.2.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGc480cXZnV-"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.2.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.2.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.2.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vh2oml4jprfv"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.2.2')"]},{"cell_type":"markdown","metadata":{"id":"9Ax6lKoVZs_v"},"source":["### 7.2.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgrcveO3Zu4g"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.2.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.2.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.2.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"px2ViBueptBI"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.2.3')"]},{"cell_type":"markdown","metadata":{"id":"y8nWdxWZZwa8"},"source":["### 7.2.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQ4DaHsZZyai"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.2.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.2.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.2.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TzLB8nFpu2L"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.2.4')"]},{"cell_type":"markdown","metadata":{"id":"pqkeD9YJ16Wi"},"source":["## 7.3 epoch = 15, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"9MB0DBQU18Yv"},"source":["### 7.3.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUbsCcIU2AAQ"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.3.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.3.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.3.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saIuX6S7pwyS"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.3.1')"]},{"cell_type":"markdown","metadata":{"id":"MSQ4GnnF2AtD"},"source":["### 7.3.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMJfYkqn2Cu-"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.3.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.3.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.3.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0raNJPzpylq"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.3.2')"]},{"cell_type":"markdown","metadata":{"id":"WfkzUKhA2DUw"},"source":["### 7.3.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6bX4MpC2I4_"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.3.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.3.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.3.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAE8I7Gzp0I7"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.3.3')"]},{"cell_type":"markdown","metadata":{"id":"QITKQVn82JgD"},"source":["### 7.3.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVLodR872Ls7"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.3.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.3.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.3.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mj3mXC8dp17o"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.3.4')"]},{"cell_type":"markdown","metadata":{"id":"Dia1Gw-pD0FN"},"source":["## 7.4 epoch = 5, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"WLOSOsVND0FN"},"source":["### 7.4.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"706t2OMkD0FN"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.4.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.4.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.4.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHPXxpTBp4Fi"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.4.1')"]},{"cell_type":"markdown","metadata":{"id":"hFtNyBbLD0FN"},"source":["### 7.4.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uWFhsOcD0FN"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.4.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.4.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.4.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dNonRpZ7p55j"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.4.2')"]},{"cell_type":"markdown","metadata":{"id":"4YZuY5OSD0FO"},"source":["### 7.4.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64MsV6QDD0FO"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.4.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.4.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.4.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZlpZtvGp7yU"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.4.3')"]},{"cell_type":"markdown","metadata":{"id":"qPyOvgpzD0FO"},"source":["### 7.4.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZmsSZGSD0FO"},"outputs":[],"source":["# without bi-directional\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.4.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.4.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.4.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXxWtRAUp9qC"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.4.4')"]},{"cell_type":"markdown","metadata":{"id":"IAQ4u3efD0FO"},"source":["## 7.5 epoch = 10, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"zdNe5yqFD0FO"},"source":["### 7.5.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfd2UcScD0FO"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.5.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.5.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.5.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVpa9z4_p_V9"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.5.1')"]},{"cell_type":"markdown","metadata":{"id":"Yj7seiiND0FP"},"source":["### 7.5.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pW7CLjWED0FP"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.5.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.5.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.5.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkrZLv8eqBMG"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.5.2')"]},{"cell_type":"markdown","metadata":{"id":"VSnHSXAND0FP"},"source":["### 7.5.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gL2E6w_D0FP"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.5.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.5.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.5.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZAaHu6uqDfD"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.5.3')"]},{"cell_type":"markdown","metadata":{"id":"xochUeOAD0FP"},"source":["### 7.5.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMQK1755D0FP"},"outputs":[],"source":["# without bi-directional\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.5.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.5.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.5.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYSWqIBGqFFk"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.5.4')"]},{"cell_type":"markdown","metadata":{"id":"ZsfA-QOaD0FQ"},"source":["## 7.6 epoch = 15, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"Ey3N-SM6D0FQ"},"source":["### 7.6.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RxhRhcjD0FR"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('noex',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.6.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.6.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.6.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZJobS59qKgN"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.6.1')"]},{"cell_type":"markdown","metadata":{"id":"EQJ2JQumD0FR"},"source":["### 7.6.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYu0qdvuD0FR"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('cross',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.6.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.6.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.6.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgBiqJ1DqM2T"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.6.2')"]},{"cell_type":"markdown","metadata":{"id":"A2Vm3BsiD0FR"},"source":["### 7.6.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0EW1c1QD0FS"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('bf',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.6.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.6.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.6.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErkswQwMqOm-"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.6.3')"]},{"cell_type":"markdown","metadata":{"id":"heQjndRND0FS"},"source":["### 7.6.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPmxTvk2D0FS"},"outputs":[],"source":["# without bi-directional\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_by_encoder_num('af',2)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"Without bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/7.6.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/7.6.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/7.6.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvaxIXhkqQQz"},"outputs":[],"source":["trans_model.save('intent-slot-domain/7/7.6.4')"]},{"cell_type":"markdown","metadata":{"id":"6FM77BJpywlO"},"source":["#8.With bi-dir"]},{"cell_type":"markdown","metadata":{"id":"CR0z8UMJZX9a"},"source":["## 8.1 epoch = 5, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"c9Dh5gI1dSxE"},"source":["### 8.1.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlJPAZ-M7_BT"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.1.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.1.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.1.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ck39g-T3qSiB"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.1.1')"]},{"cell_type":"markdown","metadata":{"id":"dOxaOnrCq3_O"},"source":["### 8.1.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YC15ouAq8dw"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.1.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.1.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.1.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQfa6N6DqVML"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.1.2')"]},{"cell_type":"markdown","metadata":{"id":"v-iv3WUiq6CN"},"source":["### 8.1.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWq27WA1q8Eb"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.1.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.1.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.1.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACStl8Q8qWzh"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.1.3')"]},{"cell_type":"markdown","metadata":{"id":"g5Mvq0xlrBbw"},"source":["### 8.1.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jyLMk3-8rEjQ"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.1.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.1.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.1.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJxTURJvqYiG"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.1.4')"]},{"cell_type":"markdown","metadata":{"id":"yrnINeCIZ6lM"},"source":["## 8.2 epoch = 10, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"Q1yY_ayqZ77p"},"source":["### 8.2.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXLqYaLiZ9kf"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.2.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.2.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.2.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozADgrb0qaSF"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.2.1')"]},{"cell_type":"markdown","metadata":{"id":"OhM606MeaFbM"},"source":["### 8.2.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfyHdQo5aIMk"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.2.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.2.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.2.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x065kD7JqcAe"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.2.2')"]},{"cell_type":"markdown","metadata":{"id":"fqFZUu9LaKGa"},"source":["### 8.2.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmD5T_kEaMEt"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.2.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.2.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.2.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbsxS5MBqefB"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.2.3')"]},{"cell_type":"markdown","metadata":{"id":"GhY5Rl-EaNqy"},"source":["### 8.2.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24FssmxoaP37"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.2.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.2.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.2.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXfM3oRiqgtH"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.2.4')"]},{"cell_type":"markdown","metadata":{"id":"lfmUFHn02bjO"},"source":["## 8.3 epoch = 15, lr = 4e-4, encoder = 1"]},{"cell_type":"markdown","metadata":{"id":"l0VuasO72gkD"},"source":["### 8.3.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIKwWlhL2czG"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.3.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.3.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.3.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vo_XQlPqiLH"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.3.1')"]},{"cell_type":"markdown","metadata":{"id":"iFiH0lCW2nsj"},"source":["### 8.3.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JR01xic2ppi"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.3.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.3.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.3.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWt7-HKvqj4c"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.3.2')"]},{"cell_type":"markdown","metadata":{"id":"FlH4Mnjb2rMx"},"source":["### 8.3.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkzU2C1b2sob"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',1)\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.3.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.3.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.3.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWTvnuqYqlMp"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.3.3')"]},{"cell_type":"markdown","metadata":{"id":"k5NrssHj2uIQ"},"source":["### 8.3.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4HMRFGb2vuW"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.3.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.3.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.3.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bY6piMTqnUs"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.3.4')"]},{"cell_type":"markdown","metadata":{"id":"QCEuzlqwEsFP"},"source":["## 8.4 epoch = 5, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"0iq8E_OnEsFP"},"source":["### 8.4.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Us_Y6nQZEsFP"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.4.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.4.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.4.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rw-1MgeQqo4l"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.4.1')"]},{"cell_type":"markdown","metadata":{"id":"UF1-LSmPEsFQ"},"source":["### 8.4.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmqvhfAcEsFQ"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.4.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.4.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.4.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9eqEynmqqG9"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.4.2')"]},{"cell_type":"markdown","metadata":{"id":"8KWRJS6yEsFQ"},"source":["### 8.4.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F5muVJWoEsFQ"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.4.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.4.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.4.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAsNquc_qrTa"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.4.3')"]},{"cell_type":"markdown","metadata":{"id":"oYinxU7ZEsFQ"},"source":["### 8.4.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4VrRjdTEsFQ"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 5\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',1)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.4.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.4.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.4.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46Mqe9urqsYs"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.4.4')"]},{"cell_type":"markdown","metadata":{"id":"KfEyuu3pEsFR"},"source":["## 8.5 epoch = 10, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"koVf02OpEsFR"},"source":["### 8.5.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Rii27bsEsFR"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.5.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.5.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.5.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puivPKeiqtz9"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.5.1')"]},{"cell_type":"markdown","metadata":{"id":"IeO9L37eEsFR"},"source":["### 8.5.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6ecm1aTEsFR"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.5.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.5.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.5.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n","\n","# print_semantic(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain, test_seq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpWD7eUUqvOu"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.5.2')"]},{"cell_type":"markdown","metadata":{"id":"iwR5MvKgEsFR"},"source":["### 8.5.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3f-vAmyEsFR"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.5.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.5.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.5.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()\n","\n","# print_semantic(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain, test_seq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-YCKZG9qwpq"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.5.3')"]},{"cell_type":"markdown","metadata":{"id":"Inu9SCjuEsFR"},"source":["### 8.5.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW7nXjOEEsFS"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 10\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.5.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.5.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.5.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSJxPjUDqxvJ"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.5.4')"]},{"cell_type":"markdown","metadata":{"id":"-_cHjcMzEsFS"},"source":["## 8.6 epoch = 15, lr = 4e-4, encoder = 2"]},{"cell_type":"markdown","metadata":{"id":"lP-8qJXiEsFS"},"source":["### 8.6.1 Noex"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQhRR3n3EsFS"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('noex',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.6.1_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.6.1_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.6.1_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijBKKiDvqzJI"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.6.1')"]},{"cell_type":"markdown","metadata":{"id":"bRvFcw-eEsFS"},"source":["### 8.6.2 Cross"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":17284,"status":"error","timestamp":1678090640302,"user":{"displayName":"Henry Weld","userId":"15950399648764551550"},"user_tz":-660},"id":"6Y02_tqzEsFS","outputId":"7c29b02e-2584-4691-c784-86468e667d9a"},"outputs":[{"ename":"InternalError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-37-21910d7c0684\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y_intent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y_domain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_slot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_intent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_domain\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 10\u001b[0;31m evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n\u001b[0m\u001b[1;32m     11\u001b[0m          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_slot_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_slot_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_intent_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_intent_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m          np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\u001b[0;32m\u003cipython-input-29-d38be10adf20\u003e\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(trans_model, slot_X_train, slot_X_test, intent_X_train, intent_X_test, domain_X_train, domain_X_test, slot_y_train, slot_y_test, intent_y_train, intent_y_test, domain_y_train, domain_y_test, batch_size, epoch, learningRate)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 24\u001b[0;31m   \u001b[0mtrans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslot_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_X_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mslot_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_y_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mtrain_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training took time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["# with bi-directional\n","\n","epoch = 1  #HW change\n","batch_size = 64   # HW change from 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('cross',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.6.2_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.6.2_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.6.2_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UH5Pnnz2q05-"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.6.2')"]},{"cell_type":"markdown","metadata":{"id":"c0hNxhBdEsFS"},"source":["### 8.6.3 BF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TM02-NzHEsFS"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 20      #HW change from 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('bf',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.6.3_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.6.3_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.6.3_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHw0zjXXq17s"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.6.3')"]},{"cell_type":"markdown","metadata":{"id":"KobPzRsgEsFT"},"source":["### 8.6.4 AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cH7HxlOmEsFT"},"outputs":[],"source":["# with bi-directional\n","\n","epoch = 15\n","batch_size = 1024\n","learningRate = 4e-4\n","\n","trans_model=get_model_bidir_by_encoder_num('af',2)\n","\n","train_acc, eval_acc, train_time, eval_time, test_Y_slot, test_Y_intent, test_Y_domain, preds_slot, preds_intent, preds_domain = \\\n","evaluate(trans_model, train_slot_bert, test_slot_bert, train_intent_bert, test_intent_bert, train_domain_bert, test_domain_bert, \\\n","         np.expand_dims(train_slot_padded, -1), np.expand_dims(test_slot_padded, -1), np.array(train_intent_transformed), np.array(test_intent_transformed),  \\\n","         np.array(train_domain_transformed), np.array(test_domain_transformed), batch_size, epoch, learningRate)\n","\n","test_Y_slot = np.squeeze(test_Y_slot, axis=-1)\n","\n","\n","evalTable = []\n","print(\"With bi-directional gates\")\n","evalTable.append([\"Training\", np.mean(train_acc), np.mean(train_time)])\n","evalTable.append([\"Evaluation\", np.mean(eval_acc), np.mean(eval_time)])\n","\n","print(\"=\"*55)\n","print(tabulate(evalTable, headers = [\"Accuracy\", \"Evaluation Time\"]))\n","print()\n","\n","semantic_error=sentence_senm(test_Y_intent, preds_intent, test_Y_slot, preds_slot, test_Y_domain, preds_domain)\n","intent_acc=intent_accuracy(test_Y_intent,preds_intent)\n","domain_acc=intent_accuracy(test_Y_domain,preds_domain)\n","slot_acc_ind, precision_ind, recall_ind, f1_ind= slot_accuracy(test_Y_slot, preds_slot)\n","\n","print(\"Slot classification report\")\n","slot_report, slot_acc, precision, recall, f1= slot_accuracy_slot_based(test_Y_slot.tolist(), preds_slot.tolist())\n","print(\"\\nIntent classification report\")\n","print(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()]))\n","print(\"\\nDomain classification report\")\n","print(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()]))\n","print()\n","\n","print(\"Semantic acc \", semantic_error)\n","print(\"Slot filling accuracy (slot-based)\", slot_acc, \" (individual-based)\", slot_acc_ind)\n","print(\"Slot filling precision (slot-based)\", precision, \" (individual-based)\", precision_ind)\n","print(\"Slot filling recall (slot-based)\", recall, \" (individual-based)\", recall_ind)\n","print(\"Slot filling F1 score (slot-based)\", f1, \" (individual-based)\", f1_ind)\n","print(\"Intent classification accuracy \", intent_acc)\n","print(\"Domain classification accuracy \", domain_acc)\n","print()\n","\n","slot_accs.append(slot_acc)\n","intent_accs.append(intent_acc)\n","domain_accs.append(domain_acc)\n","\n","\n","slot_report.style.set_table_attributes(\"style='display:inline'\").set_caption('slot_report')\n","output_path='evaluations/8.6.4_slot_cls_report.csv'\n","slot_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(slot_report, annot=True)\n","plt.title(\"Slot classification heatmap\")\n","plt.show()\n","\n","intent_report = pd.DataFrame(classification_report([ind2intent[x] for x in test_Y_intent.tolist()],[ind2intent[x] for x in preds_intent.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","intent_report.style.set_table_attributes(\"style='display:inline'\").set_caption('intent_report')\n","output_path='evaluations/8.6.4_intent_cls_report.csv'\n","intent_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(intent_report, annot=True)\n","plt.title(\"Intent classification heatmap\")\n","plt.show()\n","\n","domain_report = pd.DataFrame(classification_report([ind2domain[x] for x in test_Y_domain.tolist()],[ind2domain[x] for x in preds_domain.tolist()],output_dict=True)).iloc[:-1, :].T\n","\n","domain_report.style.set_table_attributes(\"style='display:inline'\").set_caption('domain_report')\n","output_path='evaluations/8.6.4_domain_cls_report.csv'\n","domain_report.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","sns.heatmap(domain_report, annot=True)\n","plt.title(\"Domain classification heatmap\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZIW1QZ4q3_H"},"outputs":[],"source":["trans_model.save('intent-slot-domain/8/8.6.4')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["5uSlBh7ZGV0f"],"machine_shape":"hm","name":"","provenance":[{"file_id":"1kUdpCDLjO8hcJn9otRdME4e-gaiUkJ6y","timestamp":1677653481060},{"file_id":"1XZCcyIohmH8jYvot7dxL-6q0ENZ2CJJG","timestamp":1662568712287},{"file_id":"1rhf7OGFpfSXjqwL-JYL2II8ufU0Fg4Oq","timestamp":1662567079295},{"file_id":"1DfT8UIOzAUTUz2iatxuoafVzJCHXjb9o","timestamp":1661256441475},{"file_id":"1u3RHkyxnPZvKyG3Eeipne0EUSzhyhkbQ","timestamp":1660708466573},{"file_id":"1VtQwME0oDS4CRuHCk34a1L3kxuskS9gn","timestamp":1658150355254},{"file_id":"1z-Pwc2FeojU0whox8v6wBm2xxIQmUv4V","timestamp":1656764271701},{"file_id":"1G083Wcq3dZpfZCSVbfbF9L9S1YBuNFEz","timestamp":1591606022786},{"file_id":"1OHV6LfYCX_6dNLQG8OE4JfOXCEsYWBoz","timestamp":1591333299595},{"file_id":"1-DyWmeWuR8z2F7y25N3YNFLj5J2I0pPV","timestamp":1591320863454},{"file_id":"1dFUZ5Sv67-nqY4zF85FaqzYyPOSFkdku","timestamp":1586885803444},{"file_id":"1TPLevG_zk12-AnKgHRmfJUKpFRY37kjc","timestamp":1586881246353},{"file_id":"1syyVR0pEwB9unfJo0JpH4QlfKB__9dYY","timestamp":1586850729365},{"file_id":"1E8UndIFpI1j_iDJib15wNMpx3noK0KVi","timestamp":1584004318883},{"file_id":"1V4P8x3QIOfFnrne3G3WsQSkLmV4DGT6l","timestamp":1582649840988},{"file_id":"1-aLtuFriwHcLxE0HEEtgdPj4-nXSorEm","timestamp":1570806748141},{"file_id":"1wEiTQsiQ_3-y6cOMH8vNkyFusgubmBX7","timestamp":1570712650416},{"file_id":"1IoLpn5emiYRUXcopV7b655Lqi3CvqoGL","timestamp":1570619482155},{"file_id":"1NJQtQhNpN3es7Uv3AXIT9CN4xnykUajx","timestamp":1570544876063}],"toc_visible":true,"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}